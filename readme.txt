可以将老师写的文档作为github的readme


用bert模型？做个baseline？    -》人家不是给了结果了么文献上

BR方法可能主要用机器学习的方法了

也许单层次上用bert？跟老师商量一下，不对这样的话方法不统一。主要是比较单层次和多层次的关系。
查一下文献有没有BR用神经网络的，以及多层次和单层次的文献
如果多层次和单层次比较的文献用了神经网络跟老师商量一下能不能用，年后问，但是记得先说新年快乐，然后讨论
一下是不是可以用深度学习方法
也可以用机器学习和深度学习两个方法一起做？比较，只要是分类算法就行了


深度学习的方法其实蕴含在这两种方法中
https://blog.csdn.net/u011412768/article/details/109082838
当数据量较小的时候，可以使用上面sklearn中比较传统的多标签分类模型，当数据量较多的时候，为了准确性，可以尝试直接使用深度神经网络来做多标签分类，特别是文本分类这种任务。

词向量预训练的地方可能可以改进

关于【name】【Religion】这种官方已经提前优化了
使用casual-tokenize 用来处理社交网络的非规范的包含表情符号的短文本（实验看看）
【name】的分开有问题


第一遍的时候先不用词干还原等太复杂的处理

未登录词有一定的影响看看到时候能不能改
https://www.zhihu.com/question/308543084  写文章的时候可以提一提，未登录词在【-0.25，0.25】上
均匀随机化随着模型进行微调，那个注意力惩罚的文章也提到了


nlp中多分类的标签怎么设置，是不是转为one-hot




朱老师，我汇报一下我现在的进度：
我使用nltk的TreebankWordTokenizer（第一开始用的是casual_tokenize，官方说它在网络社交文本的分词比较好，正好goemotions是从reddit里
采的文本，表情以及网络用语比较多，但是分下来发现，一些2-gram如don't都没被分成do和n't，所以暂时不用了）进行分词后， 
把属于英文的转成了小写的形式，然后用word2vec转成了词向量（暂时没有自己预训练词向量，如果后期效果不好的话尝试），
之后把[NAME]，[REGION]官方已经mask的token以及UNK进行了按[-0.25,0.25]范围随机初始化了。后面采用keras的LSTM来进行分类。
下面就是打算，按照"positive","negative","ambiguous"为第一层，采用二元法训练出3个LSTM分类器，
后面将ekman的情感划分"anger","disgust","fear","joy","sadness","surprise"训练出6个LSTM分类器，最后最细粒度的一层训练出28个LSTM分类器。总计训练出37个LSTM分类器。
如一段文本包含"nervousness“和"excitement"，根据分类器先被同时分为"negative"和"positive"两个标签，
再继续细分后同时被分为"fear"和"joy"，最后再被同时分为"nervousness“和"excitement"。

用训练样本和开发集训练和验证过模型后，在测试集上得到多标签的F1和acc最后根据goemtions的那个文献给的F1指标作为baseline对比一下有没有提高。

老师您看一下这过程中有没有问题？

基本上没有问题，不过那篇文章的指标只是对单标签分别计算相关指标，和多标签分类用的指标不一样，还是得用我给的指标。而且那篇文章的baseline用的模型本身比lstm强很多，所以baseline你实现一个做28次二分类的lstm分类器(即只用单层)就行


其实把整个过程结合起来也能画个体系图，网络结构图一定要画出来


记得每个LSTM把网络结构训练结果保存起来


根据书上，以及论文提到使用 Bi-LSTM 编码时，样本句子的长度大多都不相同，无法直接构建张量，为提
升批训练的效率，同一 batch 的编码端会以该 batch 的最长句子长度进行填充（Padding）。
进行了填充

如果最后效果不好或许可以考虑文献里的把表情符号转换到对应的单词或含义
不行就换个语料库试试
还有不要把语料库限制大小试试

可以像文献一样对loss function介绍
可以介绍一下keras，比如使用了keras提供的然后跟个keras的参考文献可以详细介绍使用的参数
可以介绍数据集详细的数据，要展示一下句子和标签
如果LSTM的效果差可以换成Bi-LSTM

受到启发由于二元下追求简单高效的类似机器学习的分类器所以使用神经网络的LSTM进行分类


注意中性情绪不包含在前两个层次！！！！！！！！！！而且中性情绪在最后一层分的时候准确率很低，或许第一层就把他分出来也是一种提高的方法？


只加载test_set
没用完一个就释放

有个猜想莫非后面的这么准确是因为0的标签比较多？而posive和negative的0，1标签比较均匀而ambiguous的0多一点

37个实在太慢就用kaggle的gpu加速看看代码要不要改成gpu加速的
多层次方法对于12，27这种neutral混杂的情况无能为力除非把前面的两层次加入27的neutral，话说为什么存在既有其他感情又有中性同时出现的合理吗？或许计算的时候忽略这种标签

如果kaggle的gpu没弄成的话看看能不能拜托学长用他们实验室的gpu请奶茶


后面开始写指标的函数，其实可以不用跑完如果太多的话，然后先把baseline弄出来，在相同的量下弄完指标后对比出结果后跟老师商榷一下，感觉还是最后一层有问题。

就是现在的问题是不是预测错（情感差别太大，确实多层次预测可以防止预测出错的标签间情感差别太大的问题）的问题，是预测不出来（大概率baseline也会存在好几个没预测出来的情况
但也有可能是预测出来的类别差太大）也就是最后一层有问题，（但或许也是情绪分类的体系有问题？应该不是）
或者我觉得可以这样如果第二层有预测出来的话第三层（或第二层）直接取概率最大的一个作为标签或进入下一层（这样也确实发挥了多层次的作用），因为这样可以比baseline时取28个里概率最大来讲更加概率大且科学。
上述想法可以和老师汇报一下
多层次从预测的效率来说可能也比单层次好






超级努力的派大星 12:29:40
也在做的过程中有我的想法和改进在里面

超级努力的派大星 12:29:50
不过先看baseline的结果

超级努力的派大星 12:34:14
第一个错分成love有很明显的原因是句子里有love这个词

超级努力的派大星 12:34:24
这些纠错的过程可以写到毕设里

超级努力的派大星 12:35:41
算法设计思想的过程里虽然简单但是工作量巨大我觉得

超级努力的派大星 13:05:12
dict

超级努力的派大星 16:27:34
每四个part的部分修改，任务书的第一部分增加一下目标和任务分开写。翻译的地方图标的题目翻译一下。综述的部分参考文献排版搞一下。增加软件的壳子。还有上面提到的东西写到readme里

超级努力的派大星 16:28:14
增加软件的壳子如能有不同数据集的输入（不是指训练是指测试集）啥的。展示。这个东西先等朱苏阳的回复

超级努力的派大星 16:30:24
实在觉得不放心也可以再问问朱旭(写到readme

超级努力的派大星 16:42:23
我觉得可以是选择或者直接写个句子作为输入的软件

超级努力的派大星 16:43:03
这么一想确实生信毕设必须弄个平台

超级努力的派大星 16:44:17
任务书要改一下，说加一些限定条件啥的，反正不能写的太简单要不然看的老师觉得太简单了

超级努力的派大星 18:10:59
超级努力的派大星  
每四个part的部分修改，任务书的第一部分增加一下目标和任务分开写。翻译的地方图标的题目翻译一下。综述的部分参考文献排版搞一下。增加软件的壳子。还有上面提到的东西写到readme里
综述的文献排版要对齐

超级努力的派大星 18:20:40
把改的东西都写到中期检查
跟朱老师说增加软件功能的同时问一下增加什么，可以把我的想法放上去


基于规则的（整数线性规划的多层次分类算法），约束



可以用三个方式都试一下然后写到论文上




超级努力的派大星 2023-04-10 16:25:56
朱老师好，我今天下午去朱晓旭老师那边做了毕设的中期检查，然后朱老师说我们光用多层次的这个方法做的太简单了，需要改一下。想请教一下老师有什么好的改进方法吗(增加点什么之类的)？



另外，目前我的进展是已经把37个训练器训练好了(第一层的三个情绪的准确率在0.83左右，其余层的训练器的准确率在0.95左右，neutral的情绪比较特殊只有0.76)，然后多层次的模型也写好了。多层次跑下来后有个现象是，有些样本得出的标签会一个也没有，原因是比如有个样本的标签是sad，然后多层次模型确实第一层把它分到了negative的类别，然后在第二层也分到了ekman的sad情绪，但是在第三层的时候sad情绪没被分出来，sigmoid出来的概率是0.37，然后我设置的阈值是0.5所以它sad的标签依然是0，第三层属于这类里其他情绪的概率，基本上为0.02很低。还有几个样本也有同样的结果。所以我有个想法是如果要发挥出多层次的优势的话，对于这种情况是不是可以取第三层里属于这类情绪中概率最大的。baseline的模型我还没写，所以目前还不清楚baseline的情况(准备晚上弄出来)，但我猜也会有同样的情况，毕竟第三层用的28个模型是一样的。

朱苏阳老师 2023-04-10 16:36:57
可以考虑在分类得到的结果上再加一些限制条件来进一步优化。具体而言，可以假设同为负面的情绪共同出现在一条文本中的概率比较高，而一正一负的情绪在统一文本中出现的概率较低。那么就可以采用一些限制条件或者规则来进一步约束得到的结果。例如某个文本被分为4类情绪，其中3负1正，并且那个正面情绪的概率不高，因此可以考虑把那个正面情绪丢掉。注意这些限制条件全都是根据常识或者对数据集的统计来人为规定的，所以要取得比较明显的效果需要多调试，修改这些限制条件的细节。除了上述的投票法之外也可以考虑使用整数线性规划来做。

可以取概率最大的，没有问题

超级努力的派大星 8:24:16
朱老师，整数线性规划具体该怎么弄呢我有点没理解。
然后我突然想起来昨天忘跟您说了，朱晓旭老师最后还说最好再加个可视化软件操作的外壳显得做的不是那么简单，可以输入不同数据集(不仅goemtions的)，我的想法是可以输入测试的句子或测试集，然后有输入的按钮以及结果展示的按钮之类的。您觉得怎么样呢

您看加上这些约束或整数线性规划和可视化软件后，审核老师应该不会再觉得做的太简单了吧？


朱苏阳老师 8:39:49
整数线性规划(ILP)的部分可以看这篇文章：corpus fusion for emotion classification。ILP和规则的区别就是一个是软限制一个是硬限制，效果其实不一定就会好

其实上面就是考虑到情感的关联性了弥补了二元方法

可视化无所谓，这个题目本身不包含可视化


已完成：
已经完成任务书填写，文献翻译，文献综述等流程。
毕设上已经完成多层次情感分类体系中的37个二元分类器的训练，多层次模型和baseline模型代码也已经完成。

存在的问题：
1.提出的模型较为简单。
2.效果欠佳。多层次模型在100个测试集上运行后的准确率为 0.443 F1值为 0.468，baseline模型准确率0.335 F1值为0.366。多层次在确实比baseline效果好，但是单独来看准确率和F1都很低。查看结果，发现存在很多没有预测出的空标签。另外baseline进行测试的时间相当长，在没有GPU的情况下100个测试句子需花费24分钟，而多层次只需要10分钟左右。另外，多层次模型在2000个测试句子上，得到Acc:  0.437 F1:  0.45的结果说明该模型的效果基本上稳定在这个范围，总共花费3小时五十分钟来测试。
解决方法：
1.在多层次模型上增加限制条件来进行优化，提高准确率和F1值。如考虑标签间的相关性，或者使用整数线性规划，以及简单的规则（对于空标签，取同层次下概率最大的作为输出）等来优化。三种方式都测试一遍。

可以展示句子
在一章中介绍基于规则的优化
用多种训练器多增加工程量
gui可能可以不用实在不行用
2.最后模型优化结束后，若有需，则使用图形用户界面来进行封装，提供可视化操作性，如能提供输入的测试句子或者更改数据集等。

P = [0.6,0.08,0.42]
[-0.584962500721156, 3.523561956057013, 0.46566357234881217]
优化结果：0.11929893
参数取值：[1, 0, 1]
 