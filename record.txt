#################################################################################################################################################################################
1.Positive_LSTM:
real_label:
[0 1 1 ... 0 1 0]
pre_prob:
[[0.9223788 ]
 [0.9848436 ]
 [0.8845648 ]
 ...
 [0.13271242]
 [0.97048527]
 [0.22312945]]
pre_label:
[[1]
 [1]
 [1]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.81113


#################################################################################################################################################################################
2.Negative_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-07 20:26:57.962675: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 92s 25ms/step - loss: 0.4781 - accuracy: 0.7876 - val_loss: 0.4270 - val_accuracy: 0.8146
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.4060 - accuracy: 0.8238 - val_loss: 0.4324 - val_accuracy: 0.8126
-----------------------------training over------------------------------------
real_label:
[1 0 0 ... 0 0 0]
pre_prob:
[[0.45713052]
 [0.01069656]
 [0.00203231]
 ...
 [0.13290197]
 [0.00163278]
 [0.1441277 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.81242




#################################################################################################################################################################################
3.Ambiguous_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-07 20:36:17.057394: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 27ms/step - loss: 0.3541 - accuracy: 0.8771 - val_loss: 0.2929 - val_accuracy: 0.8951
Epoch 2/2
1357/1357 [==============================] - 36s 26ms/step - loss: 0.3006 - accuracy: 0.8871 - val_loss: 0.2846 - val_accuracy: 0.8964
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.04814377]
 [0.06056282]
 [0.03752044]
 ...
 [0.05686346]
 [0.19700247]
 [0.0981549 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.88631



#################################################################################################################################################################################
4.Anger_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-07 20:43:10.318842: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 24ms/step - loss: 0.3576 - accuracy: 0.8700 - val_loss: 0.3233 - val_accuracy: 0.8760
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.3109 - accuracy: 0.8814 - val_loss: 0.3180 - val_accuracy: 0.8787
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00321597]
 [0.00902149]
 [0.0010882 ]
 ...
 [0.04404089]
 [0.00217405]
 [0.02619696]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.87636




#################################################################################################################################################################################
5.Disgust_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:00:02.139858: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 53s 24ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.0652 - val_accuracy: 0.9838
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0696 - accuracy: 0.9823 - val_loss: 0.0616 - val_accuracy: 0.9836
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00097504]
 [0.00154114]
 [0.00060877]
 ...
 [0.00225997]
 [0.0021776 ]
 [0.00344521]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97955





#################################################################################################################################################################################
6.Fear_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:13:31.206979: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 27ms/step - loss: 0.0886 - accuracy: 0.9800 - val_loss: 0.0605 - val_accuracy: 0.9836
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0518 - accuracy: 0.9859 - val_loss: 0.0641 - val_accuracy: 0.9838
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00687182]
 [0.00829828]
 [0.00117624]
 ...
 [0.01034755]
 [0.00543144]
 [0.02543569]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98526




#################################################################################################################################################################################
7.Joy_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:30:43.747711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 53s 25ms/step - loss: 0.5266 - accuracy: 0.7408 - val_loss: 0.4544 - val_accuracy: 0.8028
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.4412 - accuracy: 0.8058 - val_loss: 0.4648 - val_accuracy: 0.7978
-----------------------------training over------------------------------------
real_label:
[0 1 1 ... 0 1 0]
pre_prob:
[[0.84678185]
 [0.91136706]
 [0.8716495 ]
 ...
 [0.09845546]
 [0.92521685]
 [0.12643898]]
pre_label:
[[1]
 [1]
 [1]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.80155



#################################################################################################################################################################################
8.Sadness_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:35:55.524695: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 26ms/step - loss: 0.2385 - accuracy: 0.9285 - val_loss: 0.1808 - val_accuracy: 0.9438
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1851 - accuracy: 0.9414 - val_loss: 0.1809 - val_accuracy: 0.9434
-----------------------------training over------------------------------------
real_label:
[1 0 0 ... 0 0 0]
pre_prob:
[[0.74388033]
 [0.01073614]
 [0.00308749]
 ...
 [0.01753226]
 [0.02275866]
 [0.29907432]]
pre_label:
[[1]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.94325




#################################################################################################################################################################################
9.Surprise_ekman_LSTMï¼š
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:46:22.293615: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 54s 26ms/step - loss: 0.3551 - accuracy: 0.8732 - val_loss: 0.2880 - val_accuracy: 0.8933
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.2951 - accuracy: 0.8889 - val_loss: 0.2797 - val_accuracy: 0.8966
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.09028241]
 [0.05771905]
 [0.01501822]
 ...
 [0.05833566]
 [0.3374985 ]
 [0.21817902]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.88502



#################################################################################################################################################################################
10.Admiration_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:01:23.844942: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 61s 30ms/step - loss: 0.2519 - accuracy: 0.9141 - val_loss: 0.1755 - val_accuracy: 0.9355
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.1975 - accuracy: 0.9285 - val_loss: 0.1685 - val_accuracy: 0.9377
-----------------------------training over------------------------------------
real_label:
[0 1 0 ... 0 1 0]
pre_prob:
[[0.00783101]
 [0.889079  ]
 [0.30039716]
 ...
 [0.06113705]
 [0.30497426]
 [0.01298589]]
pre_label:
[[0]
 [1]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.93164


#################################################################################################################################################################################
11.Amusement_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:17:13.766730: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 27ms/step - loss: 0.1917 - accuracy: 0.9472 - val_loss: 0.1527 - val_accuracy: 0.9578
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1405 - accuracy: 0.9614 - val_loss: 0.1463 - val_accuracy: 0.9591
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.01113361]
 [0.02601084]
 [0.01749682]
 ...
 [0.01120329]
 [0.01500064]
 [0.03016058]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.96591

#################################################################################################################################################################################
12.Anger_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:26:50.306709: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 26ms/step - loss: 0.1459 - accuracy: 0.9611 - val_loss: 0.1162 - val_accuracy: 0.9665
Epoch 2/2
1357/1357 [==============================] - 35s 26ms/step - loss: 0.1062 - accuracy: 0.9677 - val_loss: 0.1157 - val_accuracy: 0.9652
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00215891]
 [0.0012269 ]
 [0.00040752]
 ...
 [0.00733227]
 [0.00015494]
 [0.00739589]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.96296



#################################################################################################################################################################################
13.Annoyance_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:32:37.120138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 59s 28ms/step - loss: 0.2265 - accuracy: 0.9368 - val_loss: 0.1980 - val_accuracy: 0.9335
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.1913 - accuracy: 0.9401 - val_loss: 0.1832 - val_accuracy: 0.9447
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00202462]
 [0.00367936]
 [0.00174686]
 ...
 [0.01536334]
 [0.00216386]
 [0.01766774]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.94214



#################################################################################################################################################################################
14.Approval_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:36:36.218630: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 26ms/step - loss: 0.2531 - accuracy: 0.9312 - val_loss: 0.2468 - val_accuracy: 0.9283
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.2220 - accuracy: 0.9351 - val_loss: 0.2388 - val_accuracy: 0.9281
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.04663086]
 [0.05315408]
 [0.06728995]
 ...
 [0.02802336]
 [0.05547681]
 [0.05140629]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.93809



#################################################################################################################################################################################
15.Caring_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:43:53.656790: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 53s 25ms/step - loss: 0.1221 - accuracy: 0.9723 - val_loss: 0.0968 - val_accuracy: 0.9718
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0862 - accuracy: 0.9760 - val_loss: 0.0940 - val_accuracy: 0.9725
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00648704]
 [0.00432205]
 [0.00735033]
 ...
 [0.01965395]
 [0.00214654]
 [0.00516695]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97605	




#################################################################################################################################################################################
16.Confusion_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:50:43.764946: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 26ms/step - loss: 0.1452 - accuracy: 0.9667 - val_loss: 0.1021 - val_accuracy: 0.9731
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1139 - accuracy: 0.9694 - val_loss: 0.0975 - val_accuracy: 0.9740
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.01543245]
 [0.01888293]
 [0.00108817]
 ...
 [0.00464895]
 [0.00733581]
 [0.01225653]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97181

#################################################################################################################################################################################	
17.Curiosity_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:55:35.920398: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 24ms/step - loss: 0.1959 - accuracy: 0.9470 - val_loss: 0.1477 - val_accuracy: 0.9552
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.1502 - accuracy: 0.9515 - val_loss: 0.1407 - val_accuracy: 0.9565
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.03540236]
 [0.01386145]
 [0.17685536]
 ...
 [0.07596251]
 [0.03642386]
 [0.01754585]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.94859



#################################################################################################################################################################################
18.Desire_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 11:31:14.202940: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 60s 28ms/step - loss: 0.0779 - accuracy: 0.9825 - val_loss: 0.0521 - val_accuracy: 0.9888
Epoch 2/2
1357/1357 [==============================] - 37s 28ms/step - loss: 0.0443 - accuracy: 0.9881 - val_loss: 0.0509 - val_accuracy: 0.9871
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00807223]
 [0.00826079]
 [0.00931472]
 ...
 [0.00304466]
 [0.00582924]
 [0.00795382]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98563


#################################################################################################################################################################################
19.Disappointment_LSTM:


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 11:36:35.623748: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 25ms/step - loss: 0.1448 - accuracy: 0.9688 - val_loss: 0.1283 - val_accuracy: 0.9698
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1143 - accuracy: 0.9716 - val_loss: 0.1220 - val_accuracy: 0.9698
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.01760879]
 [0.02713633]
 [0.0282495 ]
 ...
 [0.01849324]
 [0.01811108]
 [0.04899627]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97218





#################################################################################################################################################################################
20.Disapproval_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 11:58:09.995676: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 25ms/step - loss: 0.1885 - accuracy: 0.9528 - val_loss: 0.2184 - val_accuracy: 0.9462
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1602 - accuracy: 0.9534 - val_loss: 0.1795 - val_accuracy: 0.9464
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.02628747]
 [0.03209397]
 [0.00164789]
 ...
 [0.00585416]
 [0.00244161]
 [0.01378167]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.95099



#################################################################################################################################################################################
21.Disgust_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 12:05:36.165275: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 26ms/step - loss: 0.0974 - accuracy: 0.9806 - val_loss: 0.0676 - val_accuracy: 0.9834
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 0.0647 - val_accuracy: 0.9840
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.0022831 ]
 [0.00590357]
 [0.001385  ]
 ...
 [0.00809482]
 [0.00362936]
 [0.01090184]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97863



#################################################################################################################################################################################	
22.Embarrassment_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 12:09:47.781256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 26ms/step - loss: 0.0560 - accuracy: 0.9887 - val_loss: 0.0300 - val_accuracy: 0.9939
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.0313 - accuracy: 0.9935 - val_loss: 0.0223 - val_accuracy: 0.9954
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00123587]
 [0.00152868]
 [0.00049943]
 ...
 [0.00069758]
 [0.00386539]
 [0.00468442]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99410



#################################################################################################################################################################################	
23.Excitement_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 14:45:16.542976: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 73s 28ms/step - loss: 0.1049 - accuracy: 0.9777 - val_loss: 0.0686 - val_accuracy: 0.9840
Epoch 2/2
1357/1357 [==============================] - 33s 24ms/step - loss: 0.0752 - accuracy: 0.9814 - val_loss: 0.0697 - val_accuracy: 0.9825
-----------------------------training over------------------------------------
real_label:
[0 0 1 ... 0 0 0]
pre_prob:
[[0.00065276]
 [0.0144617 ]
 [0.38830963]
 ...
 [0.0114643 ]
 [0.01212871]
 [0.01281622]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98249






#################################################################################################################################################################################
24.Fear_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 14:55:18.060274: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 26ms/step - loss: 0.0793 - accuracy: 0.9822 - val_loss: 0.0503 - val_accuracy: 0.9849
Epoch 2/2
1357/1357 [==============================] - 33s 24ms/step - loss: 0.0441 - accuracy: 0.9882 - val_loss: 0.0500 - val_accuracy: 0.9877
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00752571]
 [0.0069893 ]
 [0.00045466]
 ...
 [0.00356585]
 [0.00274435]
 [0.0699372 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98913





#################################################################################################################################################################################
25.Gratitude_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 14:59:42.772438: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 62s 25ms/step - loss: 0.1107 - accuracy: 0.9692 - val_loss: 0.0663 - val_accuracy: 0.9836
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.0629 - accuracy: 0.9841 - val_loss: 0.0648 - val_accuracy: 0.9843
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00744769]
 [0.01329705]
 [0.04063991]
 ...
 [0.0081805 ]
 [0.07068473]
 [0.00564253]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98544


#################################################################################################################################################################################	
26.Grief_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:08:34.798770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 27ms/step - loss: 0.0262 - accuracy: 0.9957 - val_loss: 0.0118 - val_accuracy: 0.9976
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.0181 - val_accuracy: 0.9976
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[4.7354102e-03]
 [2.0260894e-05]
 [8.4549777e-07]
 ...
 [2.5278170e-05]
 [1.5738606e-04]
 [1.3157725e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99871


#################################################################################################################################################################################	
27.Joy_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:14:14.616532: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 60s 29ms/step - loss: 0.1394 - accuracy: 0.9625 - val_loss: 0.1026 - val_accuracy: 0.9696
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.0906 - val_accuracy: 0.9727
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.0103938 ]
 [0.11354861]
 [0.09610274]
 ...
 [0.02184311]
 [0.815714  ]
 [0.0518831 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.97310



#################################################################################################################################################################################	
28.Love_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:19:33.420444: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 63s 31ms/step - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.0678 - val_accuracy: 0.9748
Epoch 2/2
1357/1357 [==============================] - 38s 28ms/step - loss: 0.0642 - accuracy: 0.9769 - val_loss: 0.0681 - val_accuracy: 0.9748
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.8120199 ]
 [0.04875651]
 [0.00940102]
 ...
 [0.00889996]
 [0.00528485]
 [0.03675538]]
pre_label:
[[1]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98213





#################################################################################################################################################################################	
29.Nervousness_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:24:26.027133: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 25ms/step - loss: 0.0407 - accuracy: 0.9917 - val_loss: 0.0261 - val_accuracy: 0.9958
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 0.0228 - val_accuracy: 0.9959
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[2.3517013e-04]
 [2.5564432e-04]
 [8.0927221e-06]
 ...
 [6.7397952e-04]
 [1.3002753e-04]
 [5.5706501e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99539


#################################################################################################################################################################################	
30.Optimism_LSTM:


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:30:32.554430: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 61s 28ms/step - loss: 0.1425 - accuracy: 0.9624 - val_loss: 0.0984 - val_accuracy: 0.9725
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.0928 - accuracy: 0.9748 - val_loss: 0.0964 - val_accuracy: 0.9714
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.0021539 ]
 [0.00217506]
 [0.39054966]
 ...
 [0.00120094]
 [0.0068436 ]
 [0.00727281]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97347




#################################################################################################################################################################################	
31.Pride_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:44:25.479157: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 24ms/step - loss: 0.0277 - accuracy: 0.9974 - val_loss: 0.0136 - val_accuracy: 0.9972
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0108 - val_accuracy: 0.9983
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[6.3895524e-05]
 [1.1602890e-04]
 [1.7097592e-04]
 ...
 [8.0150366e-04]
 [1.2362599e-03]
 [1.9794703e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99760






#################################################################################################################################################################################
32.Realization_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:51:37.892475: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 61s 25ms/step - loss: 0.1273 - accuracy: 0.9728 - val_loss: 0.1041 - val_accuracy: 0.9770
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.1060 - accuracy: 0.9740 - val_loss: 0.1015 - val_accuracy: 0.9783
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.02089408]
 [0.03413433]
 [0.00192279]
 ...
 [0.00900963]
 [0.30012357]
 [0.02948651]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97402




#################################################################################################################################################################################	
33.Relief_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:56:05.110424: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 60s 26ms/step - loss: 0.0385 - accuracy: 0.9950 - val_loss: 0.0248 - val_accuracy: 0.9967
Epoch 2/2
1357/1357 [==============================] - 45s 34ms/step - loss: 0.0212 - accuracy: 0.9965 - val_loss: 0.0243 - val_accuracy: 0.9967
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00174922]
 [0.00059268]
 [0.00023431]
 ...
 [0.00029492]
 [0.06066886]
 [0.00072482]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99797




#################################################################################################################################################################################	
34.Remorse_LSTM:


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:01:04.278768: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 67s 31ms/step - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.0322 - val_accuracy: 0.9889
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0378 - val_accuracy: 0.9888
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[3.0205846e-02]
 [4.5546889e-04]
 [9.3699360e-05]
 ...
 [6.4477324e-04]
 [1.5582740e-03]
 [5.2025914e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99097




#################################################################################################################################################################################
35.Sadness_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:06:42.785759: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 28ms/step - loss: 0.1367 - accuracy: 0.9645 - val_loss: 0.0826 - val_accuracy: 0.9771
Epoch 2/2
1357/1357 [==============================] - 35s 26ms/step - loss: 0.0944 - accuracy: 0.9720 - val_loss: 0.0796 - val_accuracy: 0.9777
-----------------------------training over------------------------------------
real_label:
[1 0 0 ... 0 0 0]
pre_prob:
[[0.13366622]
 [0.01651165]
 [0.00438219]
 ...
 [0.02684006]
 [0.02303019]
 [0.06307313]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97549




#################################################################################################################################################################################	
36.Surprise_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:10:48.563182: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 26ms/step - loss: 0.1092 - accuracy: 0.9757 - val_loss: 0.0784 - val_accuracy: 0.9766
Epoch 2/2
1357/1357 [==============================] - 35s 26ms/step - loss: 0.0742 - accuracy: 0.9786 - val_loss: 0.0878 - val_accuracy: 0.9792
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00371456]
 [0.0015083 ]
 [0.00033838]
 ...
 [0.00110361]
 [0.00161746]
 [0.01236656]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97439






#################################################################################################################################################################################
37.Neutral_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:15:40.536757: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 24ms/step - loss: 0.5626 - accuracy: 0.6959 - val_loss: 0.5210 - val_accuracy: 0.7248
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.5155 - accuracy: 0.7226 - val_loss: 0.5092 - val_accuracy: 0.7331
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 1 0 1]
pre_prob:
[[0.00190479]
 [0.00563869]
 [0.07371864]
 ...
 [0.62860626]
 [0.01102319]
 [0.6041008 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [1]
 [0]
 [1]]
Accuracy: 0.73319




ä»Žå•ä¸ªäºŒåˆ†ç±»å™¨çš„å‡†ç¡®çŽ‡ä¸Šæ¥çœ‹ç¡®å®žä¹Ÿèƒ½åæ˜ å‡ºå“ªäº›æƒ…æ„Ÿæ˜¯å¥½é¢„æµ‹çš„ï¼Œæœ€impactçš„æ˜¯ç¬¬ä¸€å±‚ä»¥åŠneutralçš„å‡†ç¡®çŽ‡è¾ƒä½Ž





å¤šå±‚æ¬¡å¼€å‘é˜¶æ®µç»“æžœ


--------------------------data preprocess over--------------------------------
------------------------------i------------------------------------: 0
2023-04-10 12:00:24.877194: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll
2023-04-10 12:00:25.506529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce MX150 computeCapability: 6.1
coreClock: 1.5315GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s
2023-04-10 12:00:25.513787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-04-10 12:00:25.521587: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2023-04-10 12:00:25.529123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2023-04-10 12:00:25.536444: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2023-04-10 12:00:25.547664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2023-04-10 12:00:25.556889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2023-04-10 12:00:25.568431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2023-04-10 12:00:25.577152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2023-04-10 12:00:25.577545: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-04-10 12:00:25.578682: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-10 12:00:25.580482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-10 12:00:25.580954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      
2023-04-10 12:00:26.066758: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Positive_LSTM: predicted-probability:0.8521838188171387 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.8202412128448486 predicted-label:1
Joy_LSTM: predicted-probability:0.022903382778167725 predicted-label:0
Amusement_LSTM: predicted-probability:0.023690849542617798 predicted-label:0
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000133C225B940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Approval_LSTM: predicted-probability:0.015656501054763794 predicted-label:0
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000133BFD43AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Excitement_LSTM: predicted-probability:0.0014107227325439453 predicted-label:0
Gratitude_LSTM: predicted-probability:0.008185088634490967 predicted-label:0
Love_LSTM: predicted-probability:0.8341425657272339 predicted-label:1
Optimism_LSTM: predicted-probability:0.001503288745880127 predicted-label:0
Relief_LSTM: predicted-probability:0.002443760633468628 predicted-label:0
Pride_LSTM: predicted-probability:7.134085899451748e-05 predicted-label:0
Admiration_LSTM: predicted-probability:0.006314754486083984 predicted-label:0
Desire_LSTM: predicted-probability:0.004965275526046753 predicted-label:0
Caring_LSTM: predicted-probability:0.017183691263198853 predicted-label:0
Negative_LSTM: predicted-probability:0.627274751663208 predicted-label:1
Sadness_ekman_LSTM: predicted-probability:0.9421850442886353 predicted-label:1
Sadness_LSTM: predicted-probability:0.1015852689743042 predicted-label:0
Disappointment_LSTM: predicted-probability:0.06017473340034485 predicted-label:0
Embarrassment_LSTM: predicted-probability:0.00962841510772705 predicted-label:0
Grief_LSTM: predicted-probability:0.0006653368473052979 predicted-label:0
Remorse_LSTM: predicted-probability:0.04937338829040527 predicted-label:0
Fear_ekman_LSTM: predicted-probability:0.024012982845306396 predicted-label:0
Disgust_ekman_LSTM: predicted-probability:0.013201534748077393 predicted-label:0
Anger_ekman_LSTM: predicted-probability:0.007633805274963379 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.12520086765289307 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 1
Positive_LSTM: predicted-probability:0.9830816984176636 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.8989512920379639 predicted-label:1
Joy_LSTM: predicted-probability:0.09242680668830872 predicted-label:0
Amusement_LSTM: predicted-probability:0.023787349462509155 predicted-label:0
Approval_LSTM: predicted-probability:0.10127091407775879 predicted-label:0
Excitement_LSTM: predicted-probability:0.008249729871749878 predicted-label:0
Gratitude_LSTM: predicted-probability:0.014187335968017578 predicted-label:0
Love_LSTM: predicted-probability:0.04149600863456726 predicted-label:0
Optimism_LSTM: predicted-probability:0.006845921277999878 predicted-label:0
Relief_LSTM: predicted-probability:0.0006458759307861328 predicted-label:0
Pride_LSTM: predicted-probability:0.00017240643501281738 predicted-label:0
Admiration_LSTM: predicted-probability:0.9056823253631592 predicted-label:1
Desire_LSTM: predicted-probability:0.006334811449050903 predicted-label:0
Caring_LSTM: predicted-probability:0.004675477743148804 predicted-label:0
Negative_LSTM: predicted-probability:0.008523941040039062 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.053085654973983765 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 2
Positive_LSTM: predicted-probability:0.92753005027771 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.9136620759963989 predicted-label:1
Joy_LSTM: predicted-probability:0.0884692370891571 predicted-label:0
Amusement_LSTM: predicted-probability:0.019895583391189575 predicted-label:0
Approval_LSTM: predicted-probability:0.07140126824378967 predicted-label:0
Excitement_LSTM: predicted-probability:0.22996234893798828 predicted-label:0
Gratitude_LSTM: predicted-probability:0.02351740002632141 predicted-label:0
Love_LSTM: predicted-probability:0.007670044898986816 predicted-label:0
Optimism_LSTM: predicted-probability:0.39467552304267883 predicted-label:0
Relief_LSTM: predicted-probability:0.00037735700607299805 predicted-label:0
Pride_LSTM: predicted-probability:0.0001621246337890625 predicted-label:0
Admiration_LSTM: predicted-probability:0.3239821791648865 predicted-label:0
Desire_LSTM: predicted-probability:0.01828068494796753 predicted-label:0
Caring_LSTM: predicted-probability:0.01294735074043274 predicted-label:0
Negative_LSTM: predicted-probability:0.0025353431701660156 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.04477715492248535 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 3
Positive_LSTM: predicted-probability:0.9362878799438477 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.9183252453804016 predicted-label:1
Joy_LSTM: predicted-probability:0.01634347438812256 predicted-label:0
Amusement_LSTM: predicted-probability:0.013532072305679321 predicted-label:0
Approval_LSTM: predicted-probability:0.02779814600944519 predicted-label:0
Excitement_LSTM: predicted-probability:0.008560895919799805 predicted-label:0
Gratitude_LSTM: predicted-probability:0.9678223133087158 predicted-label:1
Love_LSTM: predicted-probability:0.00879088044166565 predicted-label:0
Optimism_LSTM: predicted-probability:0.0034666359424591064 predicted-label:0
Relief_LSTM: predicted-probability:0.0011971890926361084 predicted-label:0
Pride_LSTM: predicted-probability:0.001415163278579712 predicted-label:0
Admiration_LSTM: predicted-probability:0.012908697128295898 predicted-label:0
Desire_LSTM: predicted-probability:0.012196332216262817 predicted-label:0
Caring_LSTM: predicted-probability:0.009341388940811157 predicted-label:0
Negative_LSTM: predicted-probability:0.03259497880935669 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.1177007257938385 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 4
Positive_LSTM: predicted-probability:0.12809258699417114 predicted-label:0
Negative_LSTM: predicted-probability:0.13036853075027466 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.043657153844833374 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 5
Positive_LSTM: predicted-probability:0.9998777508735657 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.9989418387413025 predicted-label:1
Joy_LSTM: predicted-probability:0.0014043450355529785 predicted-label:0
Amusement_LSTM: predicted-probability:0.0021518170833587646 predicted-label:0
Approval_LSTM: predicted-probability:0.01645323634147644 predicted-label:0
Excitement_LSTM: predicted-probability:0.00021281838417053223 predicted-label:0
Gratitude_LSTM: predicted-probability:1.0 predicted-label:1
Love_LSTM: predicted-probability:0.000800788402557373 predicted-label:0
Optimism_LSTM: predicted-probability:0.006244361400604248 predicted-label:0
Relief_LSTM: predicted-probability:0.00014513731002807617 predicted-label:0
Pride_LSTM: predicted-probability:6.069836672395468e-05 predicted-label:0
Admiration_LSTM: predicted-probability:0.005183905363082886 predicted-label:0
Desire_LSTM: predicted-probability:0.0029998421669006348 predicted-label:0
Caring_LSTM: predicted-probability:0.01217573881149292 predicted-label:0
Negative_LSTM: predicted-probability:0.00038954615592956543 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.045381903648376465 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 6
Positive_LSTM: predicted-probability:0.26629841327667236 predicted-label:0
Negative_LSTM: predicted-probability:0.07130938768386841 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.09415382146835327 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 7
Positive_LSTM: predicted-probability:0.9725288152694702 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.8416643142700195 predicted-label:1
Joy_LSTM: predicted-probability:0.0390779972076416 predicted-label:0
Amusement_LSTM: predicted-probability:0.01778733730316162 predicted-label:0
Approval_LSTM: predicted-probability:0.04698053002357483 predicted-label:0
Excitement_LSTM: predicted-probability:0.11441391706466675 predicted-label:0
Gratitude_LSTM: predicted-probability:0.6518316864967346 predicted-label:1
Love_LSTM: predicted-probability:0.00789836049079895 predicted-label:0
Optimism_LSTM: predicted-probability:0.0015155673027038574 predicted-label:0
Relief_LSTM: predicted-probability:0.003697723150253296 predicted-label:0
Pride_LSTM: predicted-probability:0.0031624436378479004 predicted-label:0
Admiration_LSTM: predicted-probability:0.47183123230934143 predicted-label:0
Desire_LSTM: predicted-probability:0.005324453115463257 predicted-label:0
Caring_LSTM: predicted-probability:0.025832712650299072 predicted-label:0
Negative_LSTM: predicted-probability:0.018673807382583618 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.016224950551986694 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 8
Positive_LSTM: predicted-probability:0.12552911043167114 predicted-label:0
Negative_LSTM: predicted-probability:0.6694529056549072 predicted-label:1
Sadness_ekman_LSTM: predicted-probability:0.8403642177581787 predicted-label:1
Sadness_LSTM: predicted-probability:0.13991662859916687 predicted-label:0
Disappointment_LSTM: predicted-probability:0.008207231760025024 predicted-label:0
Embarrassment_LSTM: predicted-probability:0.0034036636352539062 predicted-label:0
Grief_LSTM: predicted-probability:0.009421736001968384 predicted-label:0
Remorse_LSTM: predicted-probability:0.03613382577896118 predicted-label:0
Fear_ekman_LSTM: predicted-probability:0.011398464441299438 predicted-label:0
Disgust_ekman_LSTM: predicted-probability:0.0009011030197143555 predicted-label:0
Anger_ekman_LSTM: predicted-probability:0.014240354299545288 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.023203670978546143 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 9
Positive_LSTM: predicted-probability:0.0761968195438385 predicted-label:0
Negative_LSTM: predicted-probability:0.7890483140945435 predicted-label:1
Sadness_ekman_LSTM: predicted-probability:0.5186423063278198 predicted-label:1
Sadness_LSTM: predicted-probability:0.09007331728935242 predicted-label:0
Disappointment_LSTM: predicted-probability:0.10197463631629944 predicted-label:0
Embarrassment_LSTM: predicted-probability:0.012490063905715942 predicted-label:0
Grief_LSTM: predicted-probability:1.0959574865410104e-05 predicted-label:0
Remorse_LSTM: predicted-probability:0.0007850527763366699 predicted-label:0
Fear_ekman_LSTM: predicted-probability:0.008928954601287842 predicted-label:0
Disgust_ekman_LSTM: predicted-probability:0.03724852204322815 predicted-label:0
Anger_ekman_LSTM: predicted-probability:0.2927726209163666 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.017068862915039062 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 10
Positive_LSTM: predicted-probability:0.16230809688568115 predicted-label:0
Negative_LSTM: predicted-probability:0.1312873363494873 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.07873621582984924 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 11
Positive_LSTM: predicted-probability:0.9955165982246399 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.9743020534515381 predicted-label:1
Joy_LSTM: predicted-probability:0.027285724878311157 predicted-label:0
Amusement_LSTM: predicted-probability:0.8745206594467163 predicted-label:1
Approval_LSTM: predicted-probability:0.011022597551345825 predicted-label:0
Excitement_LSTM: predicted-probability:0.005077928304672241 predicted-label:0
Gratitude_LSTM: predicted-probability:0.012977570295333862 predicted-label:0
Love_LSTM: predicted-probability:0.9179725646972656 predicted-label:1
Optimism_LSTM: predicted-probability:0.001299828290939331 predicted-label:0
Relief_LSTM: predicted-probability:0.0002592504024505615 predicted-label:0
Pride_LSTM: predicted-probability:0.00014331936836242676 predicted-label:0
Admiration_LSTM: predicted-probability:0.021532267332077026 predicted-label:0
Desire_LSTM: predicted-probability:0.00878956913948059 predicted-label:0
Caring_LSTM: predicted-probability:0.0027252137660980225 predicted-label:0
Negative_LSTM: predicted-probability:0.0029465854167938232 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.02460220456123352 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 12
Positive_LSTM: predicted-probability:0.8374795913696289 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.4755668342113495 predicted-label:0
Negative_LSTM: predicted-probability:0.17665740847587585 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.08055838942527771 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 13
Positive_LSTM: predicted-probability:0.911617636680603 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.7057175636291504 predicted-label:1
Joy_LSTM: predicted-probability:0.02299278974533081 predicted-label:0
Amusement_LSTM: predicted-probability:0.01773756742477417 predicted-label:0
Approval_LSTM: predicted-probability:0.09992355108261108 predicted-label:0
Excitement_LSTM: predicted-probability:0.010575532913208008 predicted-label:0
Gratitude_LSTM: predicted-probability:0.005793750286102295 predicted-label:0
Love_LSTM: predicted-probability:0.00329551100730896 predicted-label:0
Optimism_LSTM: predicted-probability:0.00602036714553833 predicted-label:0
Relief_LSTM: predicted-probability:0.0009829699993133545 predicted-label:0
Pride_LSTM: predicted-probability:0.00045993924140930176 predicted-label:0
Admiration_LSTM: predicted-probability:0.9366410970687866 predicted-label:1
Desire_LSTM: predicted-probability:0.006681948900222778 predicted-label:0
Caring_LSTM: predicted-probability:0.06724095344543457 predicted-label:0
Negative_LSTM: predicted-probability:0.03298747539520264 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.036642640829086304 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 14
Positive_LSTM: predicted-probability:0.4026920199394226 predicted-label:0
Negative_LSTM: predicted-probability:0.03306588530540466 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.11472469568252563 predicted-label:0
------------------------------over-------------------------------------
[['love'], ['admiration'], [], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['amusement', 'love'], [], ['admiration'], ['neutral']]


ç›®å‰æ¥çœ‹å¹¶ä¸æ˜¯ç¬¬ä¸€å±‚ï¼Œç¬¬äºŒå±‚é¢„æµ‹çš„ä¸ç¨³å®šï¼Œç¬¬ä¸€å±‚ç¬¬äºŒå±‚åŸºæœ¬ä¸Šé¢„æµ‹çš„æ˜¯æ­£ç¡®çš„ï¼ˆé™¤äº†i=12çš„ä¾‹å­ æ˜¯ç¬¬äºŒå±‚é¢„æµ‹çš„æ¦‚çŽ‡æ˜¯0.47å¯¼è‡´æ²¡èƒ½è¿›å…¥åŽé¢ç¬¬ä¸‰å±‚ï¼‰ï¼Œéƒ½æ˜¯æœ€åŽä¸€å±‚æœ¬èº«é¢„æµ‹çš„ä¸å¤ªè¡Œï¼Œè™½ç„¶éƒ½æ¯”åŒç±»é‡Œé¢„æµ‹çš„æ¦‚çŽ‡å¤§ä¸€äº›ï¼Œæ‰€ä»¥å¯¹äºŽæ²¡æœ‰æ ‡ç­¾é¢„æµ‹å‡ºæ¥çš„æƒ…å†µæ˜¯å¦è¦
å–é‡Œé¢æ¦‚çŽ‡æœ€å¤§çš„æ ‡ç­¾æœ‰å¾…å•†æ¦·ã€‚
æ‰€ä»¥è¦çœ‹çœ‹baselineçš„æƒ…å†µ



æ ·æœ¬ä¸ºåäº”çš„æƒ…å†µä¸‹çš„å¤šå±‚æ¬¡
Positive_LSTM: predicted-probability:0.8388744592666626 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.7798374891281128 predicted-label:1
Joy_LSTM: predicted-probability:0.019652128219604492 predicted-label:0
Amusement_LSTM: predicted-probability:0.007196515798568726 predicted-label:0
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000280A73CEA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Approval_LSTM: predicted-probability:0.011910587549209595 predicted-label:0
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000280A735D040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Excitement_LSTM: predicted-probability:0.001593559980392456 predicted-label:0
Gratitude_LSTM: predicted-probability:0.026866227388381958 predicted-label:0
Love_LSTM: predicted-probability:0.8112813234329224 predicted-label:1
Optimism_LSTM: predicted-probability:0.0006545484066009521 predicted-label:0
Relief_LSTM: predicted-probability:0.0008662939071655273 predicted-label:0
Pride_LSTM: predicted-probability:3.0509239877574146e-05 predicted-label:0
Admiration_LSTM: predicted-probability:0.005891352891921997 predicted-label:0
Desire_LSTM: predicted-probability:0.0033316314220428467 predicted-label:0
Caring_LSTM: predicted-probability:0.006514787673950195 predicted-label:0
Negative_LSTM: predicted-probability:0.449552059173584 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.0383685827255249 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 1
Positive_LSTM: predicted-probability:0.9725741147994995 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.8371294140815735 predicted-label:1
Joy_LSTM: predicted-probability:0.06444841623306274 predicted-label:0
Amusement_LSTM: predicted-probability:0.020375549793243408 predicted-label:0
Approval_LSTM: predicted-probability:0.05701449513435364 predicted-label:0
Excitement_LSTM: predicted-probability:0.01699867844581604 predicted-label:0
Gratitude_LSTM: predicted-probability:0.01324319839477539 predicted-label:0
Love_LSTM: predicted-probability:0.007748842239379883 predicted-label:0
Optimism_LSTM: predicted-probability:0.005267024040222168 predicted-label:0
Relief_LSTM: predicted-probability:0.0025022923946380615 predicted-label:0
Pride_LSTM: predicted-probability:0.0004234611988067627 predicted-label:0
Admiration_LSTM: predicted-probability:0.8406386375427246 predicted-label:1
Desire_LSTM: predicted-probability:0.005847930908203125 predicted-label:0
Caring_LSTM: predicted-probability:0.003241121768951416 predicted-label:0
Negative_LSTM: predicted-probability:0.044206082820892334 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.04741400480270386 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 2
Positive_LSTM: predicted-probability:0.8755757212638855 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.7842066287994385 predicted-label:1
Joy_LSTM: predicted-probability:0.0688047707080841 predicted-label:0
Amusement_LSTM: predicted-probability:0.015961140394210815 predicted-label:0
Approval_LSTM: predicted-probability:0.070637047290802 predicted-label:0
Excitement_LSTM: predicted-probability:0.09083053469657898 predicted-label:0
Gratitude_LSTM: predicted-probability:0.021232008934020996 predicted-label:0
Love_LSTM: predicted-probability:0.01420450210571289 predicted-label:0
Optimism_LSTM: predicted-probability:0.3688032031059265 predicted-label:0
Relief_LSTM: predicted-probability:0.0002701878547668457 predicted-label:0
Pride_LSTM: predicted-probability:0.000373154878616333 predicted-label:0
Admiration_LSTM: predicted-probability:0.2878824770450592 predicted-label:0
Desire_LSTM: predicted-probability:0.01410260796546936 predicted-label:0
Caring_LSTM: predicted-probability:0.011667072772979736 predicted-label:0
Negative_LSTM: predicted-probability:0.004352748394012451 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.0461273193359375 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 3
Positive_LSTM: predicted-probability:0.8920780420303345 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.8875136375427246 predicted-label:1
Joy_LSTM: predicted-probability:0.01651918888092041 predicted-label:0
Amusement_LSTM: predicted-probability:0.014127403497695923 predicted-label:0
Approval_LSTM: predicted-probability:0.029880613088607788 predicted-label:0
Excitement_LSTM: predicted-probability:0.00804951786994934 predicted-label:0
Gratitude_LSTM: predicted-probability:0.9390994310379028 predicted-label:1
Love_LSTM: predicted-probability:0.01015937328338623 predicted-label:0
Optimism_LSTM: predicted-probability:0.002856642007827759 predicted-label:0
Relief_LSTM: predicted-probability:0.0012225210666656494 predicted-label:0
Pride_LSTM: predicted-probability:0.0013227760791778564 predicted-label:0
Admiration_LSTM: predicted-probability:0.011782944202423096 predicted-label:0
Desire_LSTM: predicted-probability:0.010352283716201782 predicted-label:0
Caring_LSTM: predicted-probability:0.00795888900756836 predicted-label:0
Negative_LSTM: predicted-probability:0.04235318303108215 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.13871684670448303 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 4
Positive_LSTM: predicted-probability:0.12957763671875 predicted-label:0
Negative_LSTM: predicted-probability:0.11696124076843262 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.05420777201652527 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 5
Positive_LSTM: predicted-probability:0.9998982548713684 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.9987152814865112 predicted-label:1
Joy_LSTM: predicted-probability:0.001398622989654541 predicted-label:0
Amusement_LSTM: predicted-probability:0.0021631717681884766 predicted-label:0
Approval_LSTM: predicted-probability:0.016366004943847656 predicted-label:0
Excitement_LSTM: predicted-probability:0.00018459558486938477 predicted-label:0
Gratitude_LSTM: predicted-probability:1.0 predicted-label:1
Love_LSTM: predicted-probability:0.001664876937866211 predicted-label:0
Optimism_LSTM: predicted-probability:0.004975944757461548 predicted-label:0
Relief_LSTM: predicted-probability:0.00013709068298339844 predicted-label:0
Pride_LSTM: predicted-probability:0.00011712263221852481 predicted-label:0
Admiration_LSTM: predicted-probability:0.00482824444770813 predicted-label:0
Desire_LSTM: predicted-probability:0.002277761697769165 predicted-label:0
Caring_LSTM: predicted-probability:0.011970221996307373 predicted-label:0
Negative_LSTM: predicted-probability:0.00044283270835876465 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.06654366850852966 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 6
Positive_LSTM: predicted-probability:0.27457576990127563 predicted-label:0
Negative_LSTM: predicted-probability:0.12301293015480042 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.08834877610206604 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 7
Positive_LSTM: predicted-probability:0.9817367792129517 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.8863817453384399 predicted-label:1
Joy_LSTM: predicted-probability:0.033595651388168335 predicted-label:0
Amusement_LSTM: predicted-probability:0.018493860960006714 predicted-label:0
Approval_LSTM: predicted-probability:0.04185664653778076 predicted-label:0
Excitement_LSTM: predicted-probability:0.04836541414260864 predicted-label:0
Gratitude_LSTM: predicted-probability:0.5896838903427124 predicted-label:1
Love_LSTM: predicted-probability:0.008798569440841675 predicted-label:0
Optimism_LSTM: predicted-probability:0.0019050538539886475 predicted-label:0
Relief_LSTM: predicted-probability:0.0015183091163635254 predicted-label:0
Pride_LSTM: predicted-probability:0.0006361901760101318 predicted-label:0
Admiration_LSTM: predicted-probability:0.45458340644836426 predicted-label:0
Desire_LSTM: predicted-probability:0.003168821334838867 predicted-label:0
Caring_LSTM: predicted-probability:0.03719767928123474 predicted-label:0
Negative_LSTM: predicted-probability:0.012692093849182129 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.015392571687698364 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 8
Positive_LSTM: predicted-probability:0.1750093698501587 predicted-label:0
Negative_LSTM: predicted-probability:0.5336933135986328 predicted-label:1
Sadness_ekman_LSTM: predicted-probability:0.8158875107765198 predicted-label:1
Sadness_LSTM: predicted-probability:0.07992440462112427 predicted-label:0
Disappointment_LSTM: predicted-probability:0.004516631364822388 predicted-label:0
Embarrassment_LSTM: predicted-probability:0.004675954580307007 predicted-label:0
Grief_LSTM: predicted-probability:0.0039141178131103516 predicted-label:0
Remorse_LSTM: predicted-probability:0.06279963254928589 predicted-label:0
Fear_ekman_LSTM: predicted-probability:0.006026327610015869 predicted-label:0
Disgust_ekman_LSTM: predicted-probability:0.0018472671508789062 predicted-label:0
Anger_ekman_LSTM: predicted-probability:0.012483030557632446 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.0329933762550354 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 9
Positive_LSTM: predicted-probability:0.07689699530601501 predicted-label:0
Negative_LSTM: predicted-probability:0.7965097427368164 predicted-label:1
Sadness_ekman_LSTM: predicted-probability:0.5287523865699768 predicted-label:1
Sadness_LSTM: predicted-probability:0.10630333423614502 predicted-label:0
Disappointment_LSTM: predicted-probability:0.1045503318309784 predicted-label:0
Embarrassment_LSTM: predicted-probability:0.005417615175247192 predicted-label:0
Grief_LSTM: predicted-probability:3.105018913629465e-05 predicted-label:0
Remorse_LSTM: predicted-probability:0.0008902251720428467 predicted-label:0
Fear_ekman_LSTM: predicted-probability:0.010241061449050903 predicted-label:0
Disgust_ekman_LSTM: predicted-probability:0.039648592472076416 predicted-label:0
Anger_ekman_LSTM: predicted-probability:0.3091748356819153 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.01309734582901001 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 10
Positive_LSTM: predicted-probability:0.1315189003944397 predicted-label:0
Negative_LSTM: predicted-probability:0.12597236037254333 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.058175355195999146 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 11
Positive_LSTM: predicted-probability:0.9957761764526367 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.9792388677597046 predicted-label:1
Joy_LSTM: predicted-probability:0.030707180500030518 predicted-label:0
Amusement_LSTM: predicted-probability:0.9031509757041931 predicted-label:1
Approval_LSTM: predicted-probability:0.022126615047454834 predicted-label:0
Excitement_LSTM: predicted-probability:0.005975782871246338 predicted-label:0
Gratitude_LSTM: predicted-probability:0.014096349477767944 predicted-label:0
Love_LSTM: predicted-probability:0.9210062026977539 predicted-label:1
Optimism_LSTM: predicted-probability:0.001736462116241455 predicted-label:0
Relief_LSTM: predicted-probability:0.0005090236663818359 predicted-label:0
Pride_LSTM: predicted-probability:0.00028756260871887207 predicted-label:0
Admiration_LSTM: predicted-probability:0.03137752413749695 predicted-label:0
Desire_LSTM: predicted-probability:0.008662283420562744 predicted-label:0
Caring_LSTM: predicted-probability:0.0034118592739105225 predicted-label:0
Negative_LSTM: predicted-probability:0.0021680593490600586 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.02020186185836792 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 12
Positive_LSTM: predicted-probability:0.8998836278915405 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.6330648064613342 predicted-label:1
Joy_LSTM: predicted-probability:0.04304003715515137 predicted-label:0
Amusement_LSTM: predicted-probability:0.022639185190200806 predicted-label:0
Approval_LSTM: predicted-probability:0.11987611651420593 predicted-label:0
Excitement_LSTM: predicted-probability:0.029202550649642944 predicted-label:0
Gratitude_LSTM: predicted-probability:0.046561360359191895 predicted-label:0
Love_LSTM: predicted-probability:0.00865986943244934 predicted-label:0
Optimism_LSTM: predicted-probability:0.21166086196899414 predicted-label:0
Relief_LSTM: predicted-probability:0.004574388265609741 predicted-label:0
Pride_LSTM: predicted-probability:0.002042323350906372 predicted-label:0
Admiration_LSTM: predicted-probability:0.032246530055999756 predicted-label:0
Desire_LSTM: predicted-probability:0.6623828411102295 predicted-label:1
Caring_LSTM: predicted-probability:0.012742191553115845 predicted-label:0
Negative_LSTM: predicted-probability:0.09797036647796631 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.0528046190738678 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 13
Positive_LSTM: predicted-probability:0.9490867853164673 predicted-label:1
Joy_ekman_LSTM: predicted-probability:0.7611062526702881 predicted-label:1
Joy_LSTM: predicted-probability:0.01388975977897644 predicted-label:0
Amusement_LSTM: predicted-probability:0.013144165277481079 predicted-label:0
Approval_LSTM: predicted-probability:0.15710467100143433 predicted-label:0
Excitement_LSTM: predicted-probability:0.004884481430053711 predicted-label:0
Gratitude_LSTM: predicted-probability:0.011224299669265747 predicted-label:0
Love_LSTM: predicted-probability:0.006939679384231567 predicted-label:0
Optimism_LSTM: predicted-probability:0.009118974208831787 predicted-label:0
Relief_LSTM: predicted-probability:0.0004495978355407715 predicted-label:0
Pride_LSTM: predicted-probability:0.001074373722076416 predicted-label:0
Admiration_LSTM: predicted-probability:0.9645243883132935 predicted-label:1
Desire_LSTM: predicted-probability:0.008916914463043213 predicted-label:0
Caring_LSTM: predicted-probability:0.0848044753074646 predicted-label:0
Negative_LSTM: predicted-probability:0.012673169374465942 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.040502309799194336 predicted-label:0
------------------------------over-------------------------------------
------------------------------i------------------------------------: 14
Positive_LSTM: predicted-probability:0.4026920199394226 predicted-label:0
Negative_LSTM: predicted-probability:0.03306588530540466 predicted-label:0
Ambiguous_LSTM: predicted-probability:0.11472469568252563 predicted-label:0
------------------------------over-------------------------------------
[['love'], ['admiration'], [], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral']]
MAcc:  0.5
MF1:  0.5111111111111112






Muti_Level_Model 

test size 100  10åˆ†é’Ÿå·¦å³
------------------------------i------------------------------------: 99
------------------------------over-------------------------------------
[['love'], ['admiration'], [], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], [], [], [], ['neutral'], ['amusement', 'love'], [], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], [], [], ['neutral'], ['confusion'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], [], [], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], [], ['amusement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], [], ['gratitude'], ['neutral'], ['love', 'admiration'], [], ['neutral'], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], [], ['love'], ['admiration'], ['fear'], [], ['anger'], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], [], ['neutral'], ['neutral'], ['love'], ['gratitude'], ['love'], ['embarrassment'], ['neutral'], ['neutral'], ['surprise'], ['neutral'], ['fear'], [], ['neutral'], ['pride', 'caring']]
MAcc:  0.44333333333333336
MF1:  0.46833333333333327



Baseline_Model

test size 100  å°†è¿‘è·‘äº†24åˆ†é’Ÿ
------------------------------i------------------------------------: 99
------------------------------over-------------------------------------
[['love'], ['admiration'], [], ['gratitude'], [], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], [], [], [], ['neutral'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['admiration', 'neutral'], ['neutral'], [], ['love'], ['neutral'], [], [], ['neutral'], ['confusion'], ['neutral'], ['optimism'], ['neutral'], ['desire'], [], [], ['neutral'], ['amusement'], ['neutral'], ['neutral'], [], [], ['joy', 'admiration', 'surprise'], [], [], ['amusement'], [], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['fear'], [], ['neutral'], [], [], ['gratitude'], [], ['love', 'admiration'], [], ['desire'], ['gratitude'], [], [], [], ['desire'], ['neutral'], ['neutral'], [], ['neutral'], ['amusement'], ['neutral'], ['love'], ['admiration'], ['fear', 'neutral'], [], ['anger'], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], [], ['confusion'], [], ['love'], ['gratitude'], ['love'], ['embarrassment'], ['neutral'], [], ['surprise'], ['joy', 'neutral'], ['fear'], ['joy'], ['neutral'], ['pride', 'caring']]
MAcc:  0.3350000000000001
MF1:  0.3663333333333334

å‘çŽ°baselineæ¯”å¤šå±‚æ¬¡æ…¢çš„å¤šï¼Œä¸”ç¡®å®žå¤šå±‚æ¬¡æ›´å‡†ç¡®

ä½†å¤šå±‚æ¬¡çš„0.44ç­‰äºŽæ²¡æœ‰é¢„æµ‹éœ€è¦æ”¹å–„ï¼Œå¹¶ä¸æ˜¯ï¼Œå› ä¸ºè¿™æ˜¯å¤šæ ‡ç­¾é¢„æµ‹å·²ç»æ¯”éšæœºé¢„æµ‹å¥½å¤šäº†



Muti_Level_Model

test size 2000 3å°æ—¶äº”ååˆ†é’Ÿ


2023-04-11 11:45:33.849653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
################################Multi_Level_Model###################################
--------------------------data preprocess over--------------------------------
test size :  2000
------------------------------i------------------------------------: 0
2023-04-11 11:45:40.993338: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll
2023-04-11 11:45:41.831444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce MX150 computeCapability: 6.1
coreClock: 1.5315GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s
2023-04-11 11:45:41.835730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-04-11 11:45:41.839676: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2023-04-11 11:45:41.843244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2023-04-11 11:45:41.846768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2023-04-11 11:45:41.850828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2023-04-11 11:45:41.854406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2023-04-11 11:45:41.858012: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2023-04-11 11:45:41.861919: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2023-04-11 11:45:41.862286: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-04-11 11:45:41.863415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-11 11:45:41.864934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-11 11:45:41.865501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      
2023-04-11 11:45:42.342016: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DF996373A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DFA209BD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
------------------------------over-------------------------------------
------------------------------i------------------------------------: 1
------------------------------over-------------------------------------
------------------------------i------------------------------------: 1999
------------------------------over-------------------------------------
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], 
['neutral'], ['neutral'], [], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], [], ['amusement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['love', 'admiration'], [], [], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], 
['neutral'], ['neutral'], ['amusement'], [], ['love'], ['admiration'], ['neutral'], [], [], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], [], ['neutral'], ['neutral'], ['love'], ['gratitude'], [], ['embarrassment'], ['neutral'], ['neutral'], ['surprise'], ['neutral'], ['fear'], [], ['neutral'], ['pride', 'caring'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'],
 ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['admiration'], ['neutral'], ['optimism'], [], ['neutral'], [], ['neutral'], ['love'], ['approval'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], [], ['love'], ['curiosity'], ['neutral'], ['neutral'], ['optimism'], ['neutral'], ['fear'], [], [], ['neutral'], ['neutral'], ['neutral'], ['love'], [], 
 ['neutral'], ['disgust'], ['joy', 'admiration'], ['curiosity'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude', 'love'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['anger'], ['gratitude'], ['neutral'], ['neutral'], ['amusement'], [], ['neutral'], ['amusement'], ['neutral'], ['neutral'],
 ['pride'], ['admiration'], ['sadness'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['joy'], [], [], ['neutral'], ['admiration'], ['gratitude'], ['neutral'], ['neutral'], ['love'],
 ['admiration'], ['gratitude'], ['neutral'], ['annoyance'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['admiration'], ['sadness'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude', 'admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], 
 ['neutral'], [], ['sadness'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['fear'], ['neutral'], ['neutral'], ['disgust'], [], ['neutral'], ['admiration'], ['neutral'], [], ['neutral'], ['neutral'], [], [], ['neutral'], 
 ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['surprise'], [], ['neutral'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['admiration'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['gratitude'],
 [], ['admiration'], ['disgust'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], [], ['love'], ['gratitude'], ['neutral'], ['admiration'], ['gratitude'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['gratitude'], ['joy'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], [], 
 ['neutral'], ['neutral'], ['neutral'], ['anger'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], [], ['amusement', 'gratitude'], [], ['neutral'], ['neutral'], [], ['anger'], ['neutral'], ['anger'], ['neutral'], ['neutral'], ['joy', 'excitement'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], 
 ['neutral'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['remorse'], ['optimism'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['admiration'], [], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], [], [], ['optimism'], 
 ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['neutral'], ['approval'], ['optimism'], ['neutral'], ['love'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['anger'], ['neutral'], ['gratitude'], ['neutral'], ['amusement'], [], [], ['neutral'], ['gratitude'], ['gratitude'], [], ['love'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], 
 [], ['neutral'], ['neutral'], ['neutral'], ['love', 'admiration'], ['neutral'], ['anger'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['neutral'], ['anger'], ['anger'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['gratitude'], 
 ['neutral'], ['neutral'], ['love', 'admiration'], [], ['love'], ['neutral'], ['neutral'], ['admiration'], [], ['neutral'], ['optimism'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], [], [], [], ['neutral'], ['admiration'], [], ['neutral'], ['amusement', 'admiration'], ['neutral'], [], ['neutral'], ['neutral'], ['love'], ['gratitude'], ['desire'], ['neutral'], ['gratitude'],
 ['anger'], ['neutral'], ['gratitude'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['admiration'], [], ['neutral'], ['optimism'], ['neutral'], ['love'], ['neutral'], [], ['neutral'], ['disgust'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['optimism'], ['neutral'], ['neutral'], 
 ['gratitude'], [], [], ['neutral'], [], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['gratitude'], ['neutral'], ['gratitude', 'love'], ['neutral'], ['embarrassment'], ['gratitude'], ['neutral'], ['neutral'], ['excitement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['fear'], [], ['neutral'],
 ['neutral'], ['admiration'], ['neutral'], ['neutral'], [], [], ['neutral'], [], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['optimism'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['anger'], ['neutral'], ['admiration'], ['disgust'], ['neutral'], ['love'],
 ['admiration'], ['surprise'], ['love'], ['neutral'], ['neutral'], ['neutral'], [], ['joy', 'amusement'], ['joy', 'love'], ['neutral'], ['neutral'], [], [], ['gratitude'], ['love'], ['gratitude'], ['neutral'], [], ['neutral'], ['gratitude'], [], [], ['neutral'], ['disgust'], ['admiration'], [], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['curiosity'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], [], 
 ['neutral'], [], ['love'], ['neutral'], [], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['amusement'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], [], [], ['amusement'], ['neutral'], ['admiration'], ['love'], ['amusement', 'gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'],
 ['gratitude'], [], ['gratitude', 'admiration'], [], ['neutral'], ['admiration'], ['neutral'], [], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['admiration'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], [], ['neutral'], ['admiration'], ['admiration'], [], ['neutral'], ['anger'], ['neutral'], ['neutral'], ['optimism'], [], ['joy'], ['neutral'], ['neutral'], [], [], ['gratitude'], ['admiration'],
 [], [], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['annoyance'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'],
 ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['fear'], ['joy'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['surprise'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['amusement'], ['gratitude'], ['neutral'], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['gratitude', 'admiration'], ['neutral'], ['optimism'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], 
 [], [], ['neutral'], ['desire'], ['gratitude'], [], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['gratitude', 'admiration'], ['gratitude'], ['sadness'], ['neutral'], ['neutral'], ['gratitude'], ['gratitude', 'admiration'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], ['admiration'], ['neutral'], ['neutral'],
 [], ['amusement'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], [], ['amusement'], [], [], ['neutral'], ['remorse'], [], ['love'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['gratitude', 'admiration'], ['neutral'], ['amusement', 'gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['love'], ['neutral'], [], ['anger'], ['love'], ['neutral'],
 ['neutral'], ['gratitude'], ['admiration'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['joy', 'excitement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], [], [], ['amusement'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], 
 ['neutral'], [], [], ['neutral'], ['admiration'], ['fear'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], [], ['admiration'], ['neutral'], ['love'], ['neutral'], [], ['admiration'], ['neutral'], ['love'], ['neutral'], ['neutral'], [], [], ['gratitude'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['joy'], ['admiration'], [], ['neutral'], ['gratitude', 'optimism'], ['neutral'], ['optimism'], ['neutral'], ['neutral'], ['neutral'],
 ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['approval', 'optimism'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['love'], ['neutral'], ['joy'], ['neutral'], ['neutral'], [], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['fear'], ['neutral'], [], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], 
 [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy', 'love'], ['neutral'], ['neutral'], [], ['love'], ['neutral'], [], [], [], ['sadness'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['gratitude'], ['joy'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['fear'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love', 'desire'], ['caring'], ['neutral'], ['neutral'],
 ['neutral'], ['joy'], ['neutral'], ['optimism', 'admiration'], ['gratitude', 'admiration'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], ['gratitude', 'admiration'], ['neutral'], ['neutral'], ['anger'], [], ['neutral'], ['neutral'], ['neutral'], ['optimism'], ['neutral'], ['neutral'], ['admiration'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['joy'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['admiration'], ['gratitude'], ['neutral'], [], ['neutral'], ['surprise'], [], [], [], ['disgust'], ['neutral'], ['neutral'], [], ['neutral'], ['joy'], ['neutral'], [], ['neutral'], [], [], ['neutral'], ['neutral'], [], ['love'], [], [], ['neutral'], [], ['amusement'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['admiration'], ['admiration'], ['admiration'], ['admiration'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['curiosity'], ['neutral'], [], ['love'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['remorse', 'realization'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['desire'], [], ['neutral'], [], ['neutral'], ['love', 'admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['joy'], ['caring'], ['neutral'], ['neutral'], ['curiosity'], [], [], ['neutral'], ['neutral'], ['neutral'], ['anger'], ['neutral'], ['neutral'], ['neutral'], [], ['love', 'admiration'], ['admiration'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['gratitude'], [], ['neutral'], ['admiration'], [], ['love'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['approval'], ['disgust', 'anger'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], [], ['neutral'], ['optimism'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['excitement'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['disgust'], ['gratitude'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['gratitude'], ['optimism'], ['neutral'], ['neutral'], ['neutral'], ['embarrassment'], ['neutral'], ['joy', 'excitement'], ['gratitude', 'admiration'], [], ['neutral'], [], [], ['anger'], ['neutral'], ['sadness'], ['neutral'], ['neutral'], ['joy', 'gratitude'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['amusement'], ['neutral'], [], ['admiration'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], ['curiosity'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['excitement'], [], ['neutral'], ['gratitude'], ['neutral'], ['curiosity'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['love'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['sadness'], ['joy'], ['desire'], ['neutral'], [], ['love'], ['admiration'], ['desire'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], [], ['neutral'], ['neutral'], ['disgust'], ['curiosity'], ['neutral'], [], ['sadness'], [], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], ['joy'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['joy'], ['gratitude'], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['gratitude', 'admiration'], ['admiration'], [], ['love'], ['fear', 'nervousness'], ['neutral'], [], ['love'], ['neutral'], ['neutral'], ['admiration'], ['admiration'], ['gratitude'], ['gratitude'], ['neutral'], ['approval'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['joy'], ['gratitude'], [], ['gratitude'], ['disgust'], ['neutral'], [], ['neutral'], [], [], ['anger'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement', 'anger'], ['neutral'], ['neutral'], [], ['admiration'], [], ['joy'], ['neutral'], ['joy'], ['amusement'], ['love'], ['neutral'], ['neutral'], ['joy', 'amusement'], ['neutral'], ['neutral'], ['neutral'], ['fear'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['love'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['love'], ['admiration'], ['admiration'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['gratitude'], ['love'], ['neutral'], ['admiration'], ['joy'], [], ['admiration'], ['neutral'], ['joy', 'excitement'], ['neutral'], ['neutral'], ['admiration'], ['love'], ['neutral'], ['amusement'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love', 'optimism'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['love'], ['joy', 'love'], ['sadness'], [], ['neutral'], ['gratitude'], ['amusement'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['amusement'], [], ['gratitude'], ['gratitude'], ['admiration'], [], ['neutral'], ['neutral'], ['admiration'], ['neutral'], [], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['amusement'], ['amusement'], ['gratitude'], [], [], ['love'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love', 'admiration'], [], ['neutral'], [], ['neutral'], ['love'], [], [], [], ['love'], ['gratitude'], [], ['neutral'], [], ['neutral'], ['neutral'], ['admiration'], [], ['neutral'], ['neutral'], [], ['neutral'], ['joy'], ['neutral'], ['neutral'], ['neutral'], ['joy', 'love'], ['neutral'], ['neutral'], ['joy'], ['neutral'], [], ['neutral'], ['joy'], ['neutral'], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['joy'], [], [], ['disgust'], ['neutral'], [], ['sadness'], [], ['love'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], [], [], ['neutral'], ['love'], [], ['neutral'], ['admiration', 'sadness'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], [], ['admiration'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['optimism'], ['neutral'], ['optimism', 'admiration'], ['joy'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], [], ['admiration'], ['neutral'], [], ['neutral'], [], ['neutral'], [], ['neutral'], ['neutral'], ['joy'], ['neutral'], [], ['neutral'], ['neutral'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['love'], ['neutral'], [], ['admiration'], ['neutral'], ['curiosity'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['joy'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['admiration'], ['neutral'], [], ['joy', 'love'], ['neutral'], ['neutral'], ['neutral'], [], ['approval'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['amusement', 'gratitude'], ['admiration'], ['gratitude'], [], ['neutral'], [], ['neutral'], ['neutral'], [], ['neutral'], [], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['surprise'], ['neutral'], ['fear'], ['love'], ['neutral'], ['neutral'], [], ['neutral'], [], [], ['neutral'], ['neutral'], ['optimism'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['love'], ['neutral'], ['amusement'], ['neutral'], [], ['neutral'], ['optimism'], [], ['neutral'], ['annoyance'], ['neutral'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], [], ['admiration'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['joy'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['desire'], ['neutral'], ['annoyance'], ['neutral'], [], ['joy', 'gratitude'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['confusion', 'curiosity'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], [], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['amusement', 'admiration'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['admiration'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['optimism'], [], [], ['neutral'], ['gratitude', 'love'], ['amusement'], ['love'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude', 'admiration'], ['neutral'], ['neutral'], ['neutral'], [], ['optimism'], ['gratitude'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['joy'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['gratitude'], [], ['anger'], [], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral']]
MAcc:  0.43741666666666684
MF1:  0.4502166666666658

å…¶ä¸­é¢„æµ‹å‡ºçš„å¤šæ ‡ç­¾ä¸º54/2000
['amusement', 'love']
['love', 'admiration']
['pride', 'caring']
['joy', 'admiration']
['gratitude', 'love']
['gratitude', 'admiration']
['amusement', 'gratitude']
['joy', 'excitement']
['love', 'admiration']
['love', 'admiration']
['amusement', 'admiration']
['gratitude', 'love']
['joy', 'amusement']
['joy', 'love']
['amusement', 'gratitude']
['gratitude', 'admiration']
['gratitude', 'admiration']
['gratitude', 'admiration']
['gratitude', 'admiration']
['gratitude', 'admiration']
['amusement', 'gratitude']
['joy', 'excitement']
['gratitude', 'optimism']
['approval', 'optimism']
['joy', 'love']
['love', 'desire']
['optimism', 'admiration']
['gratitude', 'admiration']
['gratitude', 'admiration']
['remorse', 'realization']
['love', 'admiration']
['love', 'admiration']
['disgust', 'anger']
['joy', 'excitement']
['gratitude', 'admiration']
['joy', 'gratitude']
['gratitude', 'admiration']
['fear', 'nervousness']
['amusement', 'anger']
['joy', 'amusement']
['joy', 'excitement']
['love', 'optimism']
['joy', 'love']
['love', 'admiration']
['joy', 'love']
['admiration', 'sadness']
['optimism', 'admiration']
['joy', 'love']
['amusement', 'gratitude']
['joy', 'gratitude']
['confusion', 'curiosity']
['amusement', 'admiration']
['gratitude', 'love']
['gratitude', 'admiration']
54


ä»¥ä¸Šç»“æžœä¸­å¯¹å¤šæ ‡ç­¾çš„é¢„æµ‹çš„æƒ…å†µ
print(emos[24])     ['neutral']         Watch Vegan Gainsâ€™ video on that, he had it when he was like 13, highly doubt he was juicing then	6,27    confusion  neutral
print(emos[26])     ['love']           This guy is a little turd but I love him so dearly. I'll pass on your kisses :)	0,18     admiration  love
print(emos[39])     ['amusement']      in what universe? lol the mr. blue sky cover is one of the best on the album imo.	0,1    admiration amusement
print(emos[51])     []                 Get back on your meds mate..You aren't funny at all...	3,10     annoyance   disapproval





P = [0.6,0.08,0.42]
[-0.584962500721156, 3.523561956057013, 0.46566357234881217]
ä¼˜åŒ–ç»“æžœï¼š0.11929893
å‚æ•°å–å€¼ï¼š[1, 0, 1]
 
 
 
è°ƒæ•´äº†æœ€åŽä¸€å±‚çš„åˆ¤æ–­é˜ˆå€¼ä¸º0.6ï¼Œ0.7éƒ½è¯•äº†ä¸€ä¸‹ï¼Œä¸”å¯¹ç©ºæ ‡ç­¾è¿›è¡Œçš„æ”¹è¿›
ç„¶åŽç”¨äº†ILP


30ä¸ªæµ‹è¯•å•¥ä¹Ÿä¸åšçš„æ ‡å‡†
[['love'], ['admiration'], [], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['amusement', 'love'], [], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], [], ['neutral']]
MAcc:  0.43333333333333335
MF1:  0.45555555555555555
åŒæ ·å†æ¬¡æµ‹è¯•
[['love'], ['admiration'], [], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['neutral'], [], ['neutral'], ['amusement', 'love'], [], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], [], ['curiosity']]
MAcc:  0.45
MF1:  0.47777777777777775

0.6ï¼ˆ0.65ï¼‰ 30ä¸ªæµ‹è¯•åªå¯¹æœ€åŽä¸€å±‚çš„ç©ºæ ‡ç­¾è¿›è¡ŒILP
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.4666666666666667
MF1:  0.4888888888888889

0.7 30ä¸ªæ ·æœ¬æµ‹è¯• åªå¯¹æœ€åŽä¸€å±‚çš„ç©ºæ ‡ç­¾è¿›è¡ŒILP
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['admiration'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love', 'admiration'], ['neutral'], ['approval'], []]
MAcc:  0.45
MF1:  0.4666666666666667






0.65 100ä¸ªæµ‹è¯•åªå¯¹æœ€åŽä¸€å±‚çš„ç©ºæ ‡ç­¾è¿›è¡ŒILP
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], [], ['neutral'], [], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], ['approval'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['gratitude'], ['neutral'], ['love'], ['love'], [], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['caring'], ['love'], ['admiration'], ['neutral'], ['approval'], [], ['neutral'], [], ['gratitude'], [], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love'], ['gratitude'], ['love'], ['embarrassment'], ['neutral'], ['neutral'], ['surprise'], ['neutral'], ['fear'], [], ['neutral'], ['admiration']]
MAcc:  0.49
MF1:  0.5099999999999999

[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['admiration'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], ['approval'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], [], ['gratitude'], ['neutral'], ['admiration'], ['love'], [], ['gratitude'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], [], ['love'], ['admiration'], ['fear'], [], [], ['neutral'], ['neutral'], ['gratitude'], [], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love'], ['gratitude'], ['love'], ['embarrassment'], ['neutral'], ['neutral'], ['surprise'], ['neutral'], ['fear'], ['joy'], ['neutral'], ['pride', 'caring']]
MAcc:  0.4733333333333334
MF1:  0.49499999999999994





0.5 0.65 30ä¸ªæµ‹è¯• æœ€åŽä¸€å±‚
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['admiration'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], []]
MAcc:  0.43333333333333335
MF1:  0.45555555555555555

0.6ï¼ˆ0.65ï¼‰ 30ä¸ªæµ‹è¯•åªå¯¹æœ€åŽä¸€å±‚çš„ç©ºæ ‡ç­¾è¿›è¡ŒILP
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], [], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.4666666666666667
MF1:  0.4888888888888889


å› ä¸ºåˆ†è¯åŽå¯¹äºŽæœªçŸ¥çš„è¯æˆ‘æ¯æ¬¡ç”¨çš„æ˜¯randomæ¥ç”Ÿæˆçš„å‘é‡æ‰€ä»¥é¢„æµ‹ç»“æžœä¼šæœ‰æµ®åŠ¨


ä¸Šé¢çš„ILPé‡Œæœ‰äº›æ¼äº†P3.append(t_pro)ï¼Œæ‰€ä»¥æš‚æ—¶ä¸å‡†ï¼Œå½“æ—¶å°±åœ¨Joy_ekmanä¸‹åŠ äº†ä¸€ä¸ª
ä¿®æ”¹åŽçš„

0.65 30ä¾‹å­ æœ€åŽä¸€å±‚
ä¼šå‘çŽ°æ•ˆæžœå¾ˆæ˜Žæ˜¾
What's your source for that? Just curious (and yes I know it sounds like a tired contrarian statement).	7	ed7xq99
æŠŠç¬¬ä¸‰åä¸ªå¥å­çš„curiosityé¢„æµ‹å‡ºæ¥äº†

[['love'], ['admiration'], ['admiration'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['remorse'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.5833333333333334
MF1:  0.611111111111111

[['love', 'sadness'], ['admiration'], ['admiration'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['admiration'], ['sadness'], [], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.48333333333333334
MF1:  0.5111111111111111

[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['admiration'], ['sadness'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.5333333333333333
MF1:  0.5555555555555555

[['love'], ['admiration'], ['admiration'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['sadness'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.5666666666666667
MF1:  0.5888888888888888

0.65 100ä¾‹å­ï¼Œæœ€åŽä¸€å±‚
[['love'], ['admiration'], ['admiration'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['remorse'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], ['approval'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['approval'], ['neutral'], ['neutral'], ['neutral'], ['remorse'], ['gratitude'], ['neutral'], ['admiration'], ['love'], [], ['gratitude'], ['remorse'], ['neutral'], ['neutral'], [], ['neutral'], ['neutral'], ['neutral'], [], ['amusement'], ['caring'], ['love'], ['admiration'], ['neutral'], [], ['anger'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love'], ['gratitude'], ['love'], ['embarrassment'], ['neutral'], ['neutral'], ['surprise'], ['neutral'], ['disappointment', 'fear'], [], ['admiration'], ['pride']]
MAcc:  0.485
MF1:  0.5099999999999999






0.5 0.65 30ä¸ªå¥å­ åŒå±‚
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['neutral'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['fear'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.55
MF1:  0.5777777777777777

[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['sadness'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.5666666666666667
MF1:  0.5888888888888888


[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.5333333333333333
MF1:  0.5555555555555555

[['love', 'sadness'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['remorse'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.6166666666666667
MF1:  0.6444444444444444

[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['sadness'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['annoyance'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity']]
MAcc:  0.55
MF1:  0.5777777777777777






0.65 0.65 åŒå±‚
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['remorse'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.5333333333333333
MF1:  0.5555555555555555


[['love', 'remorse'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.5
MF1:  0.5222222222222223

[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['sadness'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.5333333333333333
MF1:  0.5555555555555555

[['love'], ['admiration'], ['excitement'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['remorse'], ['sadness'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.5833333333333334
MF1:  0.611111111111111

MAcc:  0.5333333333333333
MF1:  0.5666666666666667


0.6 0.65 åŒå±‚
MAcc:  0.5
MF1:  0.5222222222222223

[['love', 'sadness'], ['admiration'], ['optimism', 'admiration'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['remorse'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.5333333333333333
MF1:  0.5666666666666665

[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude', 'admiration'], ['sadness'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['neutral']]
MAcc:  0.48333333333333334
MF1:  0.5111111111111111




0.5 0.65 300ä¾‹
[['love'], ['admiration'], ['optimism'], ['gratitude'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['sadness'], ['disappointment'], ['neutral'], ['amusement', 'love'], ['desire'], ['admiration'], ['neutral'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['remorse'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['approval'], ['curiosity'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['desire'], ['neutral'], ['optimism'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['joy'], ['neutral'], ['approval'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['sadness'], ['gratitude'], ['neutral'], ['admiration'], ['love'], ['desire'], ['gratitude'], ['remorse'], ['neutral'], ['neutral'], ['desire'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['caring'], ['love', 'anger'], ['admiration'], ['fear'], ['approval'], ['love', 'anger'], ['neutral'], ['neutral'], ['gratitude'], ['curiosity'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love'], ['gratitude'], ['love'], ['embarrassment'], ['neutral'], ['neutral'], ['surprise'], ['neutral'], ['fear'], ['joy'], ['neutral'], ['pride'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['admiration'], ['neutral'], ['optimism'], ['admiration'], ['neutral'], ['excitement', 'surprise'], ['neutral'], ['love'], ['approval'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['amusement'], ['neutral'], ['love'], ['curiosity'], ['neutral'], ['neutral'], ['optimism'], ['neutral'], ['fear', 'surprise'], ['disgust'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['approval'], ['neutral'], ['disgust'], ['joy'], ['curiosity'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude', 'love'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['remorse'], ['curiosity'], ['neutral'], ['approval'], ['neutral'], ['anger'], ['gratitude'], ['neutral'], ['neutral'], ['amusement'], ['desire', 'surprise'], ['neutral'], ['amusement'], ['fear'], ['neutral'], ['pride'], ['admiration'], ['sadness'], ['approval'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['neutral'], ['anger'], ['gratitude'], ['approval'], ['neutral'], ['admiration'], ['admiration'], ['neutral'], ['approval'], ['neutral'], ['neutral'], ['fear'], ['surprise'], ['neutral'], ['disgust'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['joy'], ['optimism'], ['neutral'], ['neutral'], ['admiration'], ['gratitude'], ['neutral'], ['neutral'], ['love'], ['admiration'], ['gratitude'], ['neutral'], ['annoyance'], ['neutral'], ['neutral'], ['neutral'], ['approval'], ['neutral'], ['anger'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['admiration'], ['admiration'], ['sadness'], ['admiration'], ['neutral'], ['approval'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['love'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['gratitude', 'admiration'], ['neutral'], ['neutral'], ['admiration'], ['neutral'], ['neutral'], ['neutral'], ['desire'], ['sadness'], ['neutral'], ['neutral'], ['joy'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['disapproval'], ['neutral'], ['neutral'], ['neutral'], ['gratitude'], ['neutral'], ['gratitude'], ['disappointment'], ['sadness'], ['amusement'], ['desire'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['sadness', 'fear'], ['neutral'], ['neutral'], ['disgust'], ['love'], ['neutral'], ['admiration'], ['neutral'], ['anger'], ['neutral'], ['neutral'], ['neutral'], ['curiosity'], ['neutral'], ['approval'], ['gratitude'], ['neutral'], ['neutral'], ['neutral'], ['neutral'], ['neutral']]
MAcc:  0.4977777777777777
MF1:  0.5155555555555555