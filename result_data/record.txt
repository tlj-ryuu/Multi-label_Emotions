#################################################################################################################################################################################
1.Positive_LSTM:
real_label:
[0 1 1 ... 0 1 0]
pre_prob:
[[0.9223788 ]
 [0.9848436 ]
 [0.8845648 ]
 ...
 [0.13271242]
 [0.97048527]
 [0.22312945]]
pre_label:
[[1]
 [1]
 [1]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.81113


#################################################################################################################################################################################
2.Negative_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-07 20:26:57.962675: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 92s 25ms/step - loss: 0.4781 - accuracy: 0.7876 - val_loss: 0.4270 - val_accuracy: 0.8146
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.4060 - accuracy: 0.8238 - val_loss: 0.4324 - val_accuracy: 0.8126
-----------------------------training over------------------------------------
real_label:
[1 0 0 ... 0 0 0]
pre_prob:
[[0.45713052]
 [0.01069656]
 [0.00203231]
 ...
 [0.13290197]
 [0.00163278]
 [0.1441277 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.81242




#################################################################################################################################################################################
3.Ambiguous_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-07 20:36:17.057394: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 27ms/step - loss: 0.3541 - accuracy: 0.8771 - val_loss: 0.2929 - val_accuracy: 0.8951
Epoch 2/2
1357/1357 [==============================] - 36s 26ms/step - loss: 0.3006 - accuracy: 0.8871 - val_loss: 0.2846 - val_accuracy: 0.8964
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.04814377]
 [0.06056282]
 [0.03752044]
 ...
 [0.05686346]
 [0.19700247]
 [0.0981549 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.88631



#################################################################################################################################################################################
4.Anger_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-07 20:43:10.318842: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 24ms/step - loss: 0.3576 - accuracy: 0.8700 - val_loss: 0.3233 - val_accuracy: 0.8760
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.3109 - accuracy: 0.8814 - val_loss: 0.3180 - val_accuracy: 0.8787
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00321597]
 [0.00902149]
 [0.0010882 ]
 ...
 [0.04404089]
 [0.00217405]
 [0.02619696]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.87636




#################################################################################################################################################################################
5.Disgust_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:00:02.139858: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 53s 24ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.0652 - val_accuracy: 0.9838
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0696 - accuracy: 0.9823 - val_loss: 0.0616 - val_accuracy: 0.9836
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00097504]
 [0.00154114]
 [0.00060877]
 ...
 [0.00225997]
 [0.0021776 ]
 [0.00344521]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97955





#################################################################################################################################################################################
6.Fear_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:13:31.206979: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 27ms/step - loss: 0.0886 - accuracy: 0.9800 - val_loss: 0.0605 - val_accuracy: 0.9836
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0518 - accuracy: 0.9859 - val_loss: 0.0641 - val_accuracy: 0.9838
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00687182]
 [0.00829828]
 [0.00117624]
 ...
 [0.01034755]
 [0.00543144]
 [0.02543569]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98526




#################################################################################################################################################################################
7.Joy_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:30:43.747711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 53s 25ms/step - loss: 0.5266 - accuracy: 0.7408 - val_loss: 0.4544 - val_accuracy: 0.8028
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.4412 - accuracy: 0.8058 - val_loss: 0.4648 - val_accuracy: 0.7978
-----------------------------training over------------------------------------
real_label:
[0 1 1 ... 0 1 0]
pre_prob:
[[0.84678185]
 [0.91136706]
 [0.8716495 ]
 ...
 [0.09845546]
 [0.92521685]
 [0.12643898]]
pre_label:
[[1]
 [1]
 [1]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.80155



#################################################################################################################################################################################
8.Sadness_ekman_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:35:55.524695: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 26ms/step - loss: 0.2385 - accuracy: 0.9285 - val_loss: 0.1808 - val_accuracy: 0.9438
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1851 - accuracy: 0.9414 - val_loss: 0.1809 - val_accuracy: 0.9434
-----------------------------training over------------------------------------
real_label:
[1 0 0 ... 0 0 0]
pre_prob:
[[0.74388033]
 [0.01073614]
 [0.00308749]
 ...
 [0.01753226]
 [0.02275866]
 [0.29907432]]
pre_label:
[[1]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.94325




#################################################################################################################################################################################
9.Surprise_ekman_LSTM：
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 20:46:22.293615: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 54s 26ms/step - loss: 0.3551 - accuracy: 0.8732 - val_loss: 0.2880 - val_accuracy: 0.8933
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.2951 - accuracy: 0.8889 - val_loss: 0.2797 - val_accuracy: 0.8966
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.09028241]
 [0.05771905]
 [0.01501822]
 ...
 [0.05833566]
 [0.3374985 ]
 [0.21817902]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.88502



#################################################################################################################################################################################
10.Admiration_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:01:23.844942: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 61s 30ms/step - loss: 0.2519 - accuracy: 0.9141 - val_loss: 0.1755 - val_accuracy: 0.9355
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.1975 - accuracy: 0.9285 - val_loss: 0.1685 - val_accuracy: 0.9377
-----------------------------training over------------------------------------
real_label:
[0 1 0 ... 0 1 0]
pre_prob:
[[0.00783101]
 [0.889079  ]
 [0.30039716]
 ...
 [0.06113705]
 [0.30497426]
 [0.01298589]]
pre_label:
[[0]
 [1]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.93164


#################################################################################################################################################################################
11.Amusement_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:17:13.766730: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 27ms/step - loss: 0.1917 - accuracy: 0.9472 - val_loss: 0.1527 - val_accuracy: 0.9578
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1405 - accuracy: 0.9614 - val_loss: 0.1463 - val_accuracy: 0.9591
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.01113361]
 [0.02601084]
 [0.01749682]
 ...
 [0.01120329]
 [0.01500064]
 [0.03016058]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.96591

#################################################################################################################################################################################
12.Anger_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:26:50.306709: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 26ms/step - loss: 0.1459 - accuracy: 0.9611 - val_loss: 0.1162 - val_accuracy: 0.9665
Epoch 2/2
1357/1357 [==============================] - 35s 26ms/step - loss: 0.1062 - accuracy: 0.9677 - val_loss: 0.1157 - val_accuracy: 0.9652
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00215891]
 [0.0012269 ]
 [0.00040752]
 ...
 [0.00733227]
 [0.00015494]
 [0.00739589]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.96296



#################################################################################################################################################################################
13.Annoyance_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:32:37.120138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 59s 28ms/step - loss: 0.2265 - accuracy: 0.9368 - val_loss: 0.1980 - val_accuracy: 0.9335
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.1913 - accuracy: 0.9401 - val_loss: 0.1832 - val_accuracy: 0.9447
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00202462]
 [0.00367936]
 [0.00174686]
 ...
 [0.01536334]
 [0.00216386]
 [0.01766774]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.94214



#################################################################################################################################################################################
14.Approval_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:36:36.218630: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 26ms/step - loss: 0.2531 - accuracy: 0.9312 - val_loss: 0.2468 - val_accuracy: 0.9283
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.2220 - accuracy: 0.9351 - val_loss: 0.2388 - val_accuracy: 0.9281
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.04663086]
 [0.05315408]
 [0.06728995]
 ...
 [0.02802336]
 [0.05547681]
 [0.05140629]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.93809



#################################################################################################################################################################################
15.Caring_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:43:53.656790: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 53s 25ms/step - loss: 0.1221 - accuracy: 0.9723 - val_loss: 0.0968 - val_accuracy: 0.9718
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0862 - accuracy: 0.9760 - val_loss: 0.0940 - val_accuracy: 0.9725
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00648704]
 [0.00432205]
 [0.00735033]
 ...
 [0.01965395]
 [0.00214654]
 [0.00516695]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97605	




#################################################################################################################################################################################
16.Confusion_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:50:43.764946: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 26ms/step - loss: 0.1452 - accuracy: 0.9667 - val_loss: 0.1021 - val_accuracy: 0.9731
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1139 - accuracy: 0.9694 - val_loss: 0.0975 - val_accuracy: 0.9740
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.01543245]
 [0.01888293]
 [0.00108817]
 ...
 [0.00464895]
 [0.00733581]
 [0.01225653]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97181

#################################################################################################################################################################################	
17.Curiosity_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-08 21:55:35.920398: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 24ms/step - loss: 0.1959 - accuracy: 0.9470 - val_loss: 0.1477 - val_accuracy: 0.9552
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.1502 - accuracy: 0.9515 - val_loss: 0.1407 - val_accuracy: 0.9565
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.03540236]
 [0.01386145]
 [0.17685536]
 ...
 [0.07596251]
 [0.03642386]
 [0.01754585]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.94859



#################################################################################################################################################################################
18.Desire_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 11:31:14.202940: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 60s 28ms/step - loss: 0.0779 - accuracy: 0.9825 - val_loss: 0.0521 - val_accuracy: 0.9888
Epoch 2/2
1357/1357 [==============================] - 37s 28ms/step - loss: 0.0443 - accuracy: 0.9881 - val_loss: 0.0509 - val_accuracy: 0.9871
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00807223]
 [0.00826079]
 [0.00931472]
 ...
 [0.00304466]
 [0.00582924]
 [0.00795382]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98563


#################################################################################################################################################################################
19.Disappointment_LSTM:


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 11:36:35.623748: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 25ms/step - loss: 0.1448 - accuracy: 0.9688 - val_loss: 0.1283 - val_accuracy: 0.9698
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1143 - accuracy: 0.9716 - val_loss: 0.1220 - val_accuracy: 0.9698
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.01760879]
 [0.02713633]
 [0.0282495 ]
 ...
 [0.01849324]
 [0.01811108]
 [0.04899627]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97218





#################################################################################################################################################################################
20.Disapproval_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 11:58:09.995676: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 25ms/step - loss: 0.1885 - accuracy: 0.9528 - val_loss: 0.2184 - val_accuracy: 0.9462
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.1602 - accuracy: 0.9534 - val_loss: 0.1795 - val_accuracy: 0.9464
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.02628747]
 [0.03209397]
 [0.00164789]
 ...
 [0.00585416]
 [0.00244161]
 [0.01378167]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.95099



#################################################################################################################################################################################
21.Disgust_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 12:05:36.165275: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 26ms/step - loss: 0.0974 - accuracy: 0.9806 - val_loss: 0.0676 - val_accuracy: 0.9834
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 0.0647 - val_accuracy: 0.9840
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.0022831 ]
 [0.00590357]
 [0.001385  ]
 ...
 [0.00809482]
 [0.00362936]
 [0.01090184]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97863



#################################################################################################################################################################################	
22.Embarrassment_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 12:09:47.781256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 55s 26ms/step - loss: 0.0560 - accuracy: 0.9887 - val_loss: 0.0300 - val_accuracy: 0.9939
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.0313 - accuracy: 0.9935 - val_loss: 0.0223 - val_accuracy: 0.9954
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00123587]
 [0.00152868]
 [0.00049943]
 ...
 [0.00069758]
 [0.00386539]
 [0.00468442]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99410



#################################################################################################################################################################################	
23.Excitement_LSTM:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 14:45:16.542976: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 73s 28ms/step - loss: 0.1049 - accuracy: 0.9777 - val_loss: 0.0686 - val_accuracy: 0.9840
Epoch 2/2
1357/1357 [==============================] - 33s 24ms/step - loss: 0.0752 - accuracy: 0.9814 - val_loss: 0.0697 - val_accuracy: 0.9825
-----------------------------training over------------------------------------
real_label:
[0 0 1 ... 0 0 0]
pre_prob:
[[0.00065276]
 [0.0144617 ]
 [0.38830963]
 ...
 [0.0114643 ]
 [0.01212871]
 [0.01281622]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98249






#################################################################################################################################################################################
24.Fear_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 14:55:18.060274: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 26ms/step - loss: 0.0793 - accuracy: 0.9822 - val_loss: 0.0503 - val_accuracy: 0.9849
Epoch 2/2
1357/1357 [==============================] - 33s 24ms/step - loss: 0.0441 - accuracy: 0.9882 - val_loss: 0.0500 - val_accuracy: 0.9877
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00752571]
 [0.0069893 ]
 [0.00045466]
 ...
 [0.00356585]
 [0.00274435]
 [0.0699372 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98913





#################################################################################################################################################################################
25.Gratitude_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 14:59:42.772438: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 62s 25ms/step - loss: 0.1107 - accuracy: 0.9692 - val_loss: 0.0663 - val_accuracy: 0.9836
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.0629 - accuracy: 0.9841 - val_loss: 0.0648 - val_accuracy: 0.9843
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00744769]
 [0.01329705]
 [0.04063991]
 ...
 [0.0081805 ]
 [0.07068473]
 [0.00564253]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98544


#################################################################################################################################################################################	
26.Grief_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:08:34.798770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 56s 27ms/step - loss: 0.0262 - accuracy: 0.9957 - val_loss: 0.0118 - val_accuracy: 0.9976
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.0181 - val_accuracy: 0.9976
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[4.7354102e-03]
 [2.0260894e-05]
 [8.4549777e-07]
 ...
 [2.5278170e-05]
 [1.5738606e-04]
 [1.3157725e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99871


#################################################################################################################################################################################	
27.Joy_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:14:14.616532: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 60s 29ms/step - loss: 0.1394 - accuracy: 0.9625 - val_loss: 0.1026 - val_accuracy: 0.9696
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.0906 - val_accuracy: 0.9727
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.0103938 ]
 [0.11354861]
 [0.09610274]
 ...
 [0.02184311]
 [0.815714  ]
 [0.0518831 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.97310



#################################################################################################################################################################################	
28.Love_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:19:33.420444: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 63s 31ms/step - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.0678 - val_accuracy: 0.9748
Epoch 2/2
1357/1357 [==============================] - 38s 28ms/step - loss: 0.0642 - accuracy: 0.9769 - val_loss: 0.0681 - val_accuracy: 0.9748
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.8120199 ]
 [0.04875651]
 [0.00940102]
 ...
 [0.00889996]
 [0.00528485]
 [0.03675538]]
pre_label:
[[1]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.98213





#################################################################################################################################################################################	
29.Nervousness_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:24:26.027133: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 25ms/step - loss: 0.0407 - accuracy: 0.9917 - val_loss: 0.0261 - val_accuracy: 0.9958
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 0.0228 - val_accuracy: 0.9959
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[2.3517013e-04]
 [2.5564432e-04]
 [8.0927221e-06]
 ...
 [6.7397952e-04]
 [1.3002753e-04]
 [5.5706501e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99539


#################################################################################################################################################################################	
30.Optimism_LSTM:


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:30:32.554430: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 61s 28ms/step - loss: 0.1425 - accuracy: 0.9624 - val_loss: 0.0984 - val_accuracy: 0.9725
Epoch 2/2
1357/1357 [==============================] - 32s 23ms/step - loss: 0.0928 - accuracy: 0.9748 - val_loss: 0.0964 - val_accuracy: 0.9714
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.0021539 ]
 [0.00217506]
 [0.39054966]
 ...
 [0.00120094]
 [0.0068436 ]
 [0.00727281]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97347




#################################################################################################################################################################################	
31.Pride_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:44:25.479157: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 24ms/step - loss: 0.0277 - accuracy: 0.9974 - val_loss: 0.0136 - val_accuracy: 0.9972
Epoch 2/2
1357/1357 [==============================] - 30s 22ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0108 - val_accuracy: 0.9983
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[6.3895524e-05]
 [1.1602890e-04]
 [1.7097592e-04]
 ...
 [8.0150366e-04]
 [1.2362599e-03]
 [1.9794703e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99760






#################################################################################################################################################################################
32.Realization_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:51:37.892475: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 61s 25ms/step - loss: 0.1273 - accuracy: 0.9728 - val_loss: 0.1041 - val_accuracy: 0.9770
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.1060 - accuracy: 0.9740 - val_loss: 0.1015 - val_accuracy: 0.9783
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.02089408]
 [0.03413433]
 [0.00192279]
 ...
 [0.00900963]
 [0.30012357]
 [0.02948651]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97402




#################################################################################################################################################################################	
33.Relief_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 15:56:05.110424: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 60s 26ms/step - loss: 0.0385 - accuracy: 0.9950 - val_loss: 0.0248 - val_accuracy: 0.9967
Epoch 2/2
1357/1357 [==============================] - 45s 34ms/step - loss: 0.0212 - accuracy: 0.9965 - val_loss: 0.0243 - val_accuracy: 0.9967
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00174922]
 [0.00059268]
 [0.00023431]
 ...
 [0.00029492]
 [0.06066886]
 [0.00072482]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99797




#################################################################################################################################################################################	
34.Remorse_LSTM:


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:01:04.278768: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 67s 31ms/step - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.0322 - val_accuracy: 0.9889
Epoch 2/2
1357/1357 [==============================] - 32s 24ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0378 - val_accuracy: 0.9888
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[3.0205846e-02]
 [4.5546889e-04]
 [9.3699360e-05]
 ...
 [6.4477324e-04]
 [1.5582740e-03]
 [5.2025914e-04]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.99097




#################################################################################################################################################################################
35.Sadness_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:06:42.785759: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 28ms/step - loss: 0.1367 - accuracy: 0.9645 - val_loss: 0.0826 - val_accuracy: 0.9771
Epoch 2/2
1357/1357 [==============================] - 35s 26ms/step - loss: 0.0944 - accuracy: 0.9720 - val_loss: 0.0796 - val_accuracy: 0.9777
-----------------------------training over------------------------------------
real_label:
[1 0 0 ... 0 0 0]
pre_prob:
[[0.13366622]
 [0.01651165]
 [0.00438219]
 ...
 [0.02684006]
 [0.02303019]
 [0.06307313]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97549




#################################################################################################################################################################################	
36.Surprise_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:10:48.563182: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 58s 26ms/step - loss: 0.1092 - accuracy: 0.9757 - val_loss: 0.0784 - val_accuracy: 0.9766
Epoch 2/2
1357/1357 [==============================] - 35s 26ms/step - loss: 0.0742 - accuracy: 0.9786 - val_loss: 0.0878 - val_accuracy: 0.9792
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 0 0 0]
pre_prob:
[[0.00371456]
 [0.0015083 ]
 [0.00033838]
 ...
 [0.00110361]
 [0.00161746]
 [0.01236656]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
Accuracy: 0.97439






#################################################################################################################################################################################
37.Neutral_LSTM:

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 42, 50)            70200     
_________________________________________________________________
dropout (Dropout)            (None, 42, 50)            0         
_________________________________________________________________
flatten (Flatten)            (None, 2100)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2101      
=================================================================
Total params: 72,301
Trainable params: 72,301
Non-trainable params: 0
_________________________________________________________________
2023-04-09 16:15:40.536757: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/2
1357/1357 [==============================] - 57s 24ms/step - loss: 0.5626 - accuracy: 0.6959 - val_loss: 0.5210 - val_accuracy: 0.7248
Epoch 2/2
1357/1357 [==============================] - 31s 23ms/step - loss: 0.5155 - accuracy: 0.7226 - val_loss: 0.5092 - val_accuracy: 0.7331
-----------------------------training over------------------------------------
real_label:
[0 0 0 ... 1 0 1]
pre_prob:
[[0.00190479]
 [0.00563869]
 [0.07371864]
 ...
 [0.62860626]
 [0.01102319]
 [0.6041008 ]]
pre_label:
[[0]
 [0]
 [0]
 ...
 [1]
 [0]
 [1]]
Accuracy: 0.73319






只加载test_set
没用完一个就释放

有个猜想莫非后面的这么准确是因为0的标签比较多？而posive和negative的0，1标签比较均匀而ambiguous的0多一点

